{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "QBqp6RZee7aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1R2-bAfYe66L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5717498f-a7a4-410d-cafc-7730cc34a2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "\n",
        "from pywt import dwt\n",
        "from pywt import idwt\n",
        "import pywt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "from openpyxl.workbook import Workbook\n",
        "import pickle\n",
        "\n",
        "# Fungsi ini menetapkan nilai seed menjadi 42 untuk semua operasi acak yang dilakukan oleh TensorFlow.\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Y9n_Gu70Us8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Preprocessing"
      ],
      "metadata": {
        "id": "5UH8lcxMGsIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessing:\n",
        "        #Melakukan fungsi MinMaxScaler sesuai dengan rumus 2.11\n",
        "    def minmax_scale(df):\n",
        "        # Pemilihan fitur yang akan digunakan dan memindahkan kolom close ke paling kanan\n",
        "        FEATURES = ['Open', 'High', 'Low', 'Volume', 'Close']\n",
        "        # Memanggil objek MinMaxScaler\n",
        "        scaler = MinMaxScaler()\n",
        "        # Memasukan hasil dari minmax ke df_scaled\n",
        "        df_scaled = scaler.fit_transform(np.array(df[FEATURES]))\n",
        "\n",
        "        scaler_pred = MinMaxScaler()\n",
        "        return df_scaled, scaler_pred\n",
        "\n",
        "        # Melakukan proses denormalisasi\n",
        "    def inverse_scaler(pred, scaler):\n",
        "        pred_inversed = scaler.inverse_transform(pred)\n",
        "        return pred_inversed\n",
        "\n",
        "        # Melakukan proses splitting data\n",
        "    def splitting_data(df):\n",
        "        # Mengatur ukuran test data sebanyak 3\n",
        "        test_size = 3\n",
        "        # Mengatur ukuran train data sebanyak jumlah data - 3\n",
        "        train_size = len(df)-test_size\n",
        "        # Membagi data sesuai dengan train dan test size\n",
        "        train_data,test_data= df[0:train_size,:], df[train_size:len(df),:]\n",
        "        return train_data, test_data\n",
        "\n",
        "\n",
        "    def data_denoising(data,wavelet_type, threshold):\n",
        "        # Membuat DataFrame kosong\n",
        "        decomposed_data = pd.DataFrame(index=range(len(data)))\n",
        "        for i in range(data.shape[1]):\n",
        "            # Mendekomposisi data menggunakan pywt.dwt sesuai dengan rumus 2.13 dan 2.14\n",
        "            cA, cD = pywt.dwt(data[:, i], wavelet_type)\n",
        "\n",
        "            # Melakukan thresholding pada cD sesuai dengan rumus 2.15\n",
        "            cD_threshold = pywt.threshold(cD, threshold, mode='soft')\n",
        "\n",
        "            # Menggabungkan cA dan cD_threshold untuk merekonstruksi\n",
        "            reconstructed_data = pywt.idwt(cA, cD_threshold, wavelet_type)\n",
        "\n",
        "            # Menyimpan hasil rekonstruksi ke dalam dataframe hasil\n",
        "            decomposed_data[i] = reconstructed_data\n",
        "\n",
        "        return decomposed_data\n",
        "\n",
        "\n",
        "    def create_dataset(dataset, time_step=1, index=4):\n",
        "      # Membuat 2 array kosong sebagai data input dan target\n",
        "        dataX = []\n",
        "        dataY = []\n",
        "\n",
        "        for i in range(len(dataset)-time_step):\n",
        "            # Menetapkan nilai input\n",
        "            dataX.append(dataset[i:(i+time_step)])\n",
        "            # Menetapkan nilai close pada time-step selanjutnya sebagai target\n",
        "            dataY.append(float(dataset[i+time_step][index]))\n",
        "        return np.array(dataX), np.array(dataY)\n"
      ],
      "metadata": {
        "id": "NYn3XfonG2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Model"
      ],
      "metadata": {
        "id": "40ydH8cHGuYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def train_lstm(train_X, train_y, test_X, test_y, unit, epoch, batch):\n",
        "        # Memanggil objek Sequential dari library keras\n",
        "        model = Sequential()\n",
        "\n",
        "        # Menambahkan layer LSTM dengan unit yang ditentukan\n",
        "        # kernel_initializer diatur dengan GlorotUniform untuk inisialisasi bobot,\n",
        "        # seed = 42 artinya memastikan bahwa bobot layer diinisialisasi dengan nilai yang sama setiap kali kode dijalankan.\n",
        "        # Nilai 42 adalah nilai yang paling sering digunakan karena sifatnya yang sederhana mengacu pada penelitian Douglas Adams' “The Hitchhiker's Guide to the Galaxy,”\n",
        "        # input_shape disesuaikan dengan bentuk dari train_X\n",
        "        model.add(LSTM(unit, kernel_initializer=initializers.GlorotUniform(seed=42),\n",
        "                       input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "\n",
        "        # Menambahkan layer Dense (fully connected layer) dengan satu unit output\n",
        "        # kernel_initializer diatur dengan GlorotUniform untuk inisialisasi bobot\n",
        "        model.add(Dense(units=1, kernel_initializer=initializers.GlorotUniform(seed=42)))\n",
        "\n",
        "        # Melakukan compile pada model dengan loss function 'mae' (mean absolute error) sesuai pada rumus 2.18 dan optimizer 'adam' sesuai dengan algoritma 2.1\n",
        "        # Learning rate yang digunakan adalah default yang bernilai 0.001 sesuai dengan yang tertera pada dokumentasi library keras\n",
        "        model.compile(loss='mae',optimizer='adam')\n",
        "\n",
        "        # Melatih model dengan data train_X dan train_y\n",
        "        # Menggunakan jumlah epoch, batch_size yang ditentukan\n",
        "        # Menyediakan data validasi (test_X, test_y)\n",
        "        history = model.fit(train_X, train_y, epochs=epoch, batch_size=batch,\n",
        "                            validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "\n",
        "        return model, history\n",
        "\n",
        "    def save_model(model, category, stocks_name, hyperparam):\n",
        "        if category == 0:\n",
        "            model.save('LSTM_'+ stocks_name +str(hyperparam)+'.h5')\n",
        "        else:\n",
        "            model.save('DWT_LSTM'+ stocks_name +str(hyperparam)+'.h5')"
      ],
      "metadata": {
        "id": "HFFXkgbEG0AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Evaluation"
      ],
      "metadata": {
        "id": "XatKnp1ZG0b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluation:\n",
        "    # Fungsi untuk menghitung RMSE sesuai dengan rumus 2.17\n",
        "    def rmse(y, yhat):\n",
        "        # Menghitung perbedaan antara nilai aktual dan nilai prediksi\n",
        "        differences = [y[i] - yhat[i] for i in range(len(y))]\n",
        "        # Mengkuadratkan setiap perbedaan\n",
        "        squared_differences = [d**2 for d in differences]\n",
        "        # Menjumlahkan semua perbedaan kuadrat\n",
        "        sum_squared_differences = sum(squared_differences)\n",
        "        # Menghitung rata-rata dari perbedaan kuadrat\n",
        "        mean_squared_error = sum_squared_differences / len(y)\n",
        "        # Mengembalikan akar kuadrat dari rata-rata perbedaan kuadrat\n",
        "        return (mean_squared_error**0.5)[0]\n",
        "\n",
        "    # Fungsi untuk menghitung MAE sesuai dengan rumus 2.18\n",
        "    def mae(y, yhat):\n",
        "        # Menghitung perbedaan antara nilai aktual dan nilai prediksi\n",
        "        differences = [y[i] - yhat[i] for i in range(len(y))]\n",
        "        # Mengambil nilai absolut dari setiap perbedaan\n",
        "        absolute_differences = [abs(x) for x in differences]\n",
        "        # Menjumlahkan semua perbedaan absolut\n",
        "        sum_absolute_difference = sum(absolute_differences)\n",
        "        # Menghitung rata-rata dari perbedaan absolut\n",
        "        mean_absolute_error = sum_absolute_difference / len(y)\n",
        "        # Mengembalikan rata-rata dari perbedaan absolut\n",
        "        return mean_absolute_error[0]\n",
        "\n",
        "    # Fungsi untuk menghitung MAPE sesuai dengan rumus 2.19\n",
        "    def mape(y, yhat):\n",
        "        # Menghitung perbedaan absolut yang dibagi dengan nilai aktual\n",
        "        divided_differences = [abs((y[i] - yhat[i])/y[i]) for i in range(len(y))]\n",
        "        # Menjumlahkan semua perbedaan absolut yang dibagi\n",
        "        sum_absolute_difference = sum(divided_differences)\n",
        "        # Menghitung rata-rata dari perbedaan absolut yang dibagi\n",
        "        mean_absolute_percentage_error = sum_absolute_difference / len(y)\n",
        "        # Mengembalikan rata-rata persentase kesalahan absolut dikalikan 100\n",
        "        return (mean_absolute_percentage_error*100)[0]"
      ],
      "metadata": {
        "id": "OVo5Axa2Hbku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "X-07BkzhHk43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca dataframe melalui google drive\n",
        "BBCA_dfd= pd.read_csv('/content/drive/MyDrive/Data/BBCA.JK.csv')\n",
        "BBCA_dfd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b-XUtuCm_j_1",
        "outputId": "b792c02e-df4a-4b84-fbd0-66e68a9cfd3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date    Open    High     Low   Close    Adj Close     Volume\n",
              "0     2019-01-16  5260.0  5285.0  5245.0  5285.0  4813.968262   94972500\n",
              "1     2019-01-17  5290.0  5330.0  5285.0  5330.0  4854.957520   91654000\n",
              "2     2019-01-18  5340.0  5425.0  5315.0  5425.0  4941.490234  100873500\n",
              "3     2019-01-21  5425.0  5600.0  5390.0  5545.0  5050.795410   87118000\n",
              "4     2019-01-22  5600.0  5620.0  5450.0  5600.0  5100.893066   91907000\n",
              "...          ...     ...     ...     ...     ...          ...        ...\n",
              "1226  2024-01-09  9600.0  9625.0  9575.0  9625.0  9625.000000   59848600\n",
              "1227  2024-01-10  9650.0  9650.0  9550.0  9550.0  9550.000000   52774900\n",
              "1228  2024-01-11  9625.0  9650.0  9575.0  9575.0  9575.000000   39381500\n",
              "1229  2024-01-12  9650.0  9700.0  9600.0  9700.0  9700.000000   68253400\n",
              "1230  2024-01-15  9700.0  9700.0  9700.0  9700.0  9700.000000          0\n",
              "\n",
              "[1231 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9ae9b0c-4bb6-4f69-84c9-81199ed89ea5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-16</td>\n",
              "      <td>5260.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>5245.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>4813.968262</td>\n",
              "      <td>94972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>5290.0</td>\n",
              "      <td>5330.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>5330.0</td>\n",
              "      <td>4854.957520</td>\n",
              "      <td>91654000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>5340.0</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>5315.0</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>4941.490234</td>\n",
              "      <td>100873500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-21</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5390.0</td>\n",
              "      <td>5545.0</td>\n",
              "      <td>5050.795410</td>\n",
              "      <td>87118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-22</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5620.0</td>\n",
              "      <td>5450.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5100.893066</td>\n",
              "      <td>91907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>2024-01-09</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9625.000000</td>\n",
              "      <td>59848600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>2024-01-10</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9550.0</td>\n",
              "      <td>9550.0</td>\n",
              "      <td>9550.000000</td>\n",
              "      <td>52774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228</th>\n",
              "      <td>2024-01-11</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9575.000000</td>\n",
              "      <td>39381500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>2024-01-12</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.000000</td>\n",
              "      <td>68253400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1231 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9ae9b0c-4bb6-4f69-84c9-81199ed89ea5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9ae9b0c-4bb6-4f69-84c9-81199ed89ea5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9ae9b0c-4bb6-4f69-84c9-81199ed89ea5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1dd0b978-bc16-4243-941f-623c85d098ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1dd0b978-bc16-4243-941f-623c85d098ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1dd0b978-bc16-4243-941f-623c85d098ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "BBCA_dfd",
              "summary": "{\n  \"name\": \"BBCA_dfd\",\n  \"rows\": 1231,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1231,\n        \"samples\": [\n          \"2021-03-31\",\n          \"2023-04-12\",\n          \"2019-12-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1263.1991404297676,\n        \"min\": 4450.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 384,\n        \"samples\": [\n          6555.0,\n          6850.0,\n          8975.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1266.5980246818408,\n        \"min\": 4800.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 385,\n        \"samples\": [\n          6665.0,\n          7300.0,\n          8825.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1266.5402526803089,\n        \"min\": 4325.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 386,\n        \"samples\": [\n          8500.0,\n          7650.0,\n          6015.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1267.9580245002148,\n        \"min\": 4430.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 392,\n        \"samples\": [\n          6040.0,\n          6225.0,\n          7160.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1394.7166833799854,\n        \"min\": 4084.944092,\n        \"max\": 9700.0,\n        \"num_unique_values\": 636,\n        \"samples\": [\n          5262.461426,\n          9475.0,\n          5551.970703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54463534,\n        \"min\": 0,\n        \"max\": 722827900,\n        \"num_unique_values\": 1214,\n        \"samples\": [\n          71945100,\n          62776200,\n          51527000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Normalization"
      ],
      "metadata": {
        "id": "9d62VNJKMLA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan Nomalisasi data\n",
        "x,scaler = Preprocessing.minmax_scale(BBCA_dfd)"
      ],
      "metadata": {
        "id": "TqYLczYjAG3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data kelima fitur yang dinormalisasi : ')\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxI5cdFnAHDb",
        "outputId": "fe296494-c3b5-4586-df0a-c7e95af7bc8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data kelima fitur yang dinormalisasi : \n",
            "[[0.15428571 0.09897959 0.17116279 0.1313902  0.16223909]\n",
            " [0.16       0.10816327 0.17860465 0.1267992  0.17077799]\n",
            " [0.16952381 0.12755102 0.18418605 0.13955397 0.18880455]\n",
            " ...\n",
            " [0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]\n",
            " [0.99047619 1.         0.98139535 0.09442552 1.        ]\n",
            " [1.         1.         1.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "hsAGVc1HMSc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Melakukan splitting data\n",
        "train,test = Preprocessing.splitting_data(x)"
      ],
      "metadata": {
        "id": "AuSQcElO00LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data :\")\n",
        "print(train)\n",
        "print(\"=========================================================\")\n",
        "print(\"Testing Data :\")\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTgV6TvfLbIT",
        "outputId": "3bb912f1-6a34-4520-cfe6-9918ae6cb0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data :\n",
            "[[0.15428571 0.09897959 0.17116279 0.1313902  0.16223909]\n",
            " [0.16       0.10816327 0.17860465 0.1267992  0.17077799]\n",
            " [0.16952381 0.12755102 0.18418605 0.13955397 0.18880455]\n",
            " ...\n",
            " [0.98095238 0.98469388 0.95813953 0.07041233 0.97628083]\n",
            " [0.98095238 0.98469388 0.97674419 0.08279786 0.9857685 ]\n",
            " [0.99047619 0.98979592 0.97209302 0.07301171 0.971537  ]]\n",
            "=========================================================\n",
            "Testing Data :\n",
            "[[0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]\n",
            " [0.99047619 1.         0.98139535 0.09442552 1.        ]\n",
            " [1.         1.         1.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Denoising"
      ],
      "metadata": {
        "id": "ZIf2smd2Ngr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Menginisialisasi threshold dan jenis wavelet yang akan digunakan\n",
        "threshold = 0.004\n",
        "wavelet_type = 'haar'\n",
        "#  Melakukan proses denoising data menggunakan DWT\n",
        "denoised_train = Preprocessing.data_denoising(train,wavelet_type,threshold)"
      ],
      "metadata": {
        "id": "7kHHfsM0M1WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hasil data training yang telah bersih dari noise \")\n",
        "print(denoised_train.values)\n",
        "print(len(denoised_train.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KusC9tiGOW3V",
        "outputId": "39aa5531-936b-4e59-c4dd-393bcb60f0d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil data training yang telah bersih dari noise \n",
            "[[0.15711414 0.10180802 0.17399122 0.1290947  0.16506752]\n",
            " [0.15717157 0.10533484 0.17577622 0.1290947  0.16794956]\n",
            " [0.17235224 0.13037945 0.18701447 0.13672554 0.19163298]\n",
            " ...\n",
            " [0.97812395 0.98214286 0.95813953 0.07324076 0.97628083]\n",
            " [0.98378081 0.9872449  0.9744186  0.07996943 0.98294007]\n",
            " [0.98764776 0.9872449  0.9744186  0.07584014 0.97436543]]\n",
            "1228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Dataset"
      ],
      "metadata": {
        "id": "8RoDl3dNS8w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membagi data train dan test menjadi input dan target\n",
        "train_X, train_y = Preprocessing.create_dataset(denoised_train.values)\n",
        "test_X, test_y = Preprocessing.create_dataset(test)"
      ],
      "metadata": {
        "id": "lSzRoqZ8PhMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data train_X\")\n",
        "print(\"=====================================\")\n",
        "print(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlqpujilR0xA",
        "outputId": "b13a525b-fa13-42a7-b7a3-b3ab364d7cd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train_X\n",
            "=====================================\n",
            "[[[0.15711414 0.10180802 0.17399122 0.1290947  0.16506752]]\n",
            "\n",
            " [[0.15717157 0.10533484 0.17577622 0.1290947  0.16794956]]\n",
            "\n",
            " [[0.17235224 0.13037945 0.18701447 0.13672554 0.19163298]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.96473319 0.98214286 0.95813953 0.1151666  0.97628083]]\n",
            "\n",
            " [[0.97812395 0.98214286 0.95813953 0.07324076 0.97628083]]\n",
            "\n",
            " [[0.98378081 0.9872449  0.9744186  0.07996943 0.98294007]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data train_y\")\n",
        "print(\"=====================================\")\n",
        "print(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhBdjYFoTknR",
        "outputId": "e1dc3895-924e-493f-9fcd-73c2b3f72882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train_y\n",
            "=====================================\n",
            "[0.16794956 0.19163298 0.20874653 ... 0.97628083 0.98294007 0.97436543]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data test_X\")\n",
        "print(\"=====================================\")\n",
        "print(test_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR7SG6s3T1rO",
        "outputId": "16472676-fba5-42e5-d2d2-80df8d37ecec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data test_X\n",
            "=====================================\n",
            "[[[0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]]\n",
            "\n",
            " [[0.99047619 1.         0.98139535 0.09442552 1.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data test_y\")\n",
        "print(\"=====================================\")\n",
        "print(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q14XzOx_UanI",
        "outputId": "237e994b-e44e-447f-b8bd-738763a6b1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data test_y\n",
            "=====================================\n",
            "[1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Hyperparameter Combination"
      ],
      "metadata": {
        "id": "v9lceIehU5ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = []\n",
        "batch = [16, 32]\n",
        "epoch = [50, 100]\n",
        "neuron = [20,50]\n",
        "for j in batch:\n",
        "    for k in epoch:\n",
        "        for l in neuron:\n",
        "            hyperparams.append((j,k,l))\n",
        "hyperparams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMpZ4ISZUgOr",
        "outputId": "66eca373-15fd-46a0-9f2b-5e8d884b6428"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 50, 20),\n",
              " (16, 50, 50),\n",
              " (16, 100, 20),\n",
              " (16, 100, 50),\n",
              " (32, 50, 20),\n",
              " (32, 50, 50),\n",
              " (32, 100, 20),\n",
              " (32, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam1 = hyperparams[:4]\n",
        "hyperparam2 = hyperparams[4:8]\n",
        "hyperparam1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g90mOo39VmvE",
        "outputId": "2420e9a8-4de4-4fcd-d233-7b7e15ec64d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 50, 20), (16, 50, 50), (16, 100, 20), (16, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUlU0nSDWJvz",
        "outputId": "7cd5616c-c422-47f6-ae49-c9cbdea78017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(32, 50, 20), (32, 50, 50), (32, 100, 20), (32, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Model"
      ],
      "metadata": {
        "id": "IAogp9HYXKIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstms1 = []\n",
        "models1 = []\n",
        "for batch, epoch, neuron in hyperparam1:\n",
        "    model, lstm = NeuralNetwork.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
        "    lstms1.append(lstm)\n",
        "    models1.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_DX2E7FWLrd",
        "outputId": "83e3f739-f917-46c3-da38-32057d191d63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "77/77 - 3s - loss: 0.1456 - val_loss: 0.0130 - 3s/epoch - 34ms/step\n",
            "Epoch 2/50\n",
            "77/77 - 0s - loss: 0.0519 - val_loss: 0.0443 - 176ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "77/77 - 0s - loss: 0.0405 - val_loss: 0.0264 - 181ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "77/77 - 0s - loss: 0.0315 - val_loss: 0.0193 - 179ms/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "77/77 - 0s - loss: 0.0231 - val_loss: 0.0313 - 177ms/epoch - 2ms/step\n",
            "Epoch 6/50\n",
            "77/77 - 0s - loss: 0.0181 - val_loss: 0.0282 - 171ms/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "77/77 - 0s - loss: 0.0155 - val_loss: 0.0233 - 188ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0212 - 173ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0196 - 192ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0212 - 186ms/epoch - 2ms/step\n",
            "Epoch 11/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0198 - 174ms/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0197 - 180ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0211 - 177ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0186 - 205ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0214 - 179ms/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0200 - 173ms/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0215 - 184ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0200 - 191ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0182 - 176ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0201 - 195ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0203 - 176ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0224 - 180ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0202 - 180ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0225 - 178ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0219 - 207ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0197 - 177ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0205 - 208ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0216 - 254ms/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0201 - 246ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0223 - 270ms/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0227 - 246ms/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0207 - 230ms/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0210 - 264ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0223 - 284ms/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0196 - 239ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0211 - 267ms/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0199 - 269ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0215 - 299ms/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0224 - 263ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0221 - 253ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0238 - 268ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0235 - 287ms/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0204 - 211ms/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0215 - 182ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0230 - 177ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0223 - 182ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0223 - 183ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0217 - 172ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0201 - 176ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0205 - 173ms/epoch - 2ms/step\n",
            "Epoch 1/50\n",
            "77/77 - 3s - loss: 0.1189 - val_loss: 0.0384 - 3s/epoch - 34ms/step\n",
            "Epoch 2/50\n",
            "77/77 - 0s - loss: 0.0484 - val_loss: 0.0390 - 187ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "77/77 - 0s - loss: 0.0367 - val_loss: 0.0338 - 185ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "77/77 - 0s - loss: 0.0287 - val_loss: 0.0258 - 202ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "77/77 - 0s - loss: 0.0233 - val_loss: 0.0107 - 195ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "77/77 - 0s - loss: 0.0179 - val_loss: 0.0061 - 188ms/epoch - 2ms/step\n",
            "Epoch 7/50\n",
            "77/77 - 0s - loss: 0.0153 - val_loss: 0.0060 - 189ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0062 - 189ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0063 - 192ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0063 - 207ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0064 - 185ms/epoch - 2ms/step\n",
            "Epoch 12/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 185ms/epoch - 2ms/step\n",
            "Epoch 13/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 188ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 187ms/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0063 - 208ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 196ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 186ms/epoch - 2ms/step\n",
            "Epoch 18/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0065 - 187ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 184ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0065 - 197ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0065 - 193ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 187ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0066 - 188ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 191ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 188ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 207ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 198ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 192ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 215ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0068 - 190ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0067 - 289ms/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0067 - 281ms/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0067 - 245ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0068 - 274ms/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0068 - 271ms/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 280ms/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0068 - 255ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 292ms/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0069 - 292ms/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0080 - 285ms/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 329ms/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 292ms/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0070 - 283ms/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 318ms/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0123 - 332ms/epoch - 4ms/step\n",
            "Epoch 46/50\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0069 - 206ms/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0069 - 192ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0116 - 185ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0069 - 200ms/epoch - 3ms/step\n",
            "Epoch 50/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0094 - 202ms/epoch - 3ms/step\n",
            "Epoch 1/100\n",
            "77/77 - 4s - loss: 0.1456 - val_loss: 0.0130 - 4s/epoch - 50ms/step\n",
            "Epoch 2/100\n",
            "77/77 - 0s - loss: 0.0519 - val_loss: 0.0443 - 302ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "77/77 - 0s - loss: 0.0405 - val_loss: 0.0264 - 216ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "77/77 - 0s - loss: 0.0315 - val_loss: 0.0193 - 186ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "77/77 - 0s - loss: 0.0231 - val_loss: 0.0313 - 179ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "77/77 - 0s - loss: 0.0181 - val_loss: 0.0282 - 182ms/epoch - 2ms/step\n",
            "Epoch 7/100\n",
            "77/77 - 0s - loss: 0.0155 - val_loss: 0.0233 - 179ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0212 - 171ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0196 - 192ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0212 - 175ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0198 - 177ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0197 - 180ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0211 - 176ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0186 - 175ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0214 - 184ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0200 - 172ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0215 - 174ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0200 - 174ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0182 - 183ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0201 - 182ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0203 - 191ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0224 - 179ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0202 - 175ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0225 - 169ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0219 - 172ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0197 - 186ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0205 - 178ms/epoch - 2ms/step\n",
            "Epoch 28/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0216 - 184ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0201 - 177ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0223 - 176ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0227 - 174ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0207 - 183ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0210 - 174ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0223 - 181ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0196 - 171ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0211 - 174ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0199 - 172ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0215 - 185ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0224 - 176ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0221 - 179ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0238 - 184ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0235 - 196ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0204 - 180ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0215 - 171ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0230 - 185ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0223 - 179ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0223 - 173ms/epoch - 2ms/step\n",
            "Epoch 48/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0217 - 176ms/epoch - 2ms/step\n",
            "Epoch 49/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0201 - 189ms/epoch - 2ms/step\n",
            "Epoch 50/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0205 - 184ms/epoch - 2ms/step\n",
            "Epoch 51/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0219 - 183ms/epoch - 2ms/step\n",
            "Epoch 52/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0238 - 174ms/epoch - 2ms/step\n",
            "Epoch 53/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0215 - 175ms/epoch - 2ms/step\n",
            "Epoch 54/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0237 - 178ms/epoch - 2ms/step\n",
            "Epoch 55/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0215 - 196ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0206 - 184ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0226 - 175ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0228 - 238ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0218 - 239ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0210 - 246ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0228 - 240ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0231 - 238ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0231 - 217ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0219 - 263ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0215 - 229ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0214 - 233ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0222 - 233ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0217 - 263ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0225 - 265ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0223 - 281ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0212 - 264ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0220 - 281ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0207 - 245ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0214 - 269ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0217 - 254ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0231 - 248ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0242 - 179ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0222 - 177ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0225 - 179ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0215 - 179ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0211 - 176ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0213 - 190ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0225 - 175ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0223 - 185ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0234 - 179ms/epoch - 2ms/step\n",
            "Epoch 86/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0220 - 176ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0210 - 197ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0218 - 180ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0213 - 175ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0202 - 176ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0227 - 176ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0210 - 178ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0237 - 180ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0237 - 167ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0222 - 179ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "77/77 - 0s - loss: 0.0135 - val_loss: 0.0199 - 176ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0211 - 180ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0210 - 176ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0209 - 184ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0218 - 172ms/epoch - 2ms/step\n",
            "Epoch 1/100\n",
            "77/77 - 3s - loss: 0.1189 - val_loss: 0.0384 - 3s/epoch - 38ms/step\n",
            "Epoch 2/100\n",
            "77/77 - 0s - loss: 0.0484 - val_loss: 0.0390 - 178ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "77/77 - 0s - loss: 0.0367 - val_loss: 0.0338 - 187ms/epoch - 2ms/step\n",
            "Epoch 4/100\n",
            "77/77 - 0s - loss: 0.0287 - val_loss: 0.0258 - 174ms/epoch - 2ms/step\n",
            "Epoch 5/100\n",
            "77/77 - 0s - loss: 0.0233 - val_loss: 0.0107 - 186ms/epoch - 2ms/step\n",
            "Epoch 6/100\n",
            "77/77 - 0s - loss: 0.0179 - val_loss: 0.0061 - 205ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "77/77 - 0s - loss: 0.0153 - val_loss: 0.0060 - 206ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0062 - 190ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0063 - 190ms/epoch - 2ms/step\n",
            "Epoch 10/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0063 - 183ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0064 - 195ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 184ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 190ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 182ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0063 - 190ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 184ms/epoch - 2ms/step\n",
            "Epoch 17/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 198ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0065 - 191ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 192ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0065 - 197ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0065 - 190ms/epoch - 2ms/step\n",
            "Epoch 22/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 189ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0066 - 180ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 179ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 178ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 184ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 199ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 189ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0067 - 183ms/epoch - 2ms/step\n",
            "Epoch 30/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0068 - 184ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0067 - 183ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0067 - 180ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0067 - 201ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0068 - 182ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0068 - 192ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 184ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0068 - 185ms/epoch - 2ms/step\n",
            "Epoch 38/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 197ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0069 - 188ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0080 - 181ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0068 - 181ms/epoch - 2ms/step\n",
            "Epoch 42/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 183ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0070 - 189ms/epoch - 2ms/step\n",
            "Epoch 44/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 224ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0123 - 255ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0069 - 241ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0069 - 246ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0116 - 247ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0069 - 238ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0094 - 258ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0129 - 275ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0069 - 267ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0090 - 227ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0105 - 281ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0070 - 295ms/epoch - 4ms/step\n",
            "Epoch 56/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0110 - 278ms/epoch - 4ms/step\n",
            "Epoch 57/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0075 - 275ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0111 - 264ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0113 - 246ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0126 - 286ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0142 - 228ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0072 - 195ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0118 - 184ms/epoch - 2ms/step\n",
            "Epoch 64/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0111 - 208ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0122 - 176ms/epoch - 2ms/step\n",
            "Epoch 66/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0125 - 182ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0096 - 186ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0142 - 182ms/epoch - 2ms/step\n",
            "Epoch 69/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0135 - 183ms/epoch - 2ms/step\n",
            "Epoch 70/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0118 - 192ms/epoch - 2ms/step\n",
            "Epoch 71/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0072 - 187ms/epoch - 2ms/step\n",
            "Epoch 72/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0120 - 185ms/epoch - 2ms/step\n",
            "Epoch 73/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0120 - 181ms/epoch - 2ms/step\n",
            "Epoch 74/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0126 - 193ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0112 - 189ms/epoch - 2ms/step\n",
            "Epoch 76/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0129 - 178ms/epoch - 2ms/step\n",
            "Epoch 77/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0132 - 180ms/epoch - 2ms/step\n",
            "Epoch 78/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0114 - 193ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0134 - 180ms/epoch - 2ms/step\n",
            "Epoch 80/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0140 - 181ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "77/77 - 0s - loss: 0.0135 - val_loss: 0.0113 - 193ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0122 - 178ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0115 - 195ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0107 - 177ms/epoch - 2ms/step\n",
            "Epoch 85/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0139 - 194ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0150 - 191ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "77/77 - 0s - loss: 0.0134 - val_loss: 0.0112 - 185ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0155 - 181ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "77/77 - 0s - loss: 0.0134 - val_loss: 0.0117 - 182ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0157 - 180ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0153 - 182ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "77/77 - 0s - loss: 0.0134 - val_loss: 0.0118 - 198ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0169 - 185ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "77/77 - 0s - loss: 0.0135 - val_loss: 0.0117 - 189ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0159 - 191ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "77/77 - 0s - loss: 0.0134 - val_loss: 0.0112 - 189ms/epoch - 2ms/step\n",
            "Epoch 97/100\n",
            "77/77 - 0s - loss: 0.0134 - val_loss: 0.0117 - 188ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "77/77 - 0s - loss: 0.0135 - val_loss: 0.0120 - 177ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "77/77 - 0s - loss: 0.0135 - val_loss: 0.0114 - 185ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0158 - 187ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model"
      ],
      "metadata": {
        "id": "4qRW8VgDZYmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "wb1 = Workbook()\n",
        "ws1 = wb1.active\n",
        "for m in models1:\n",
        "    # make a prediction\n",
        "    test_x2 = test_X\n",
        "    yhat = m.predict(test_x2)\n",
        "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
        "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
        "    print(hyperparam1[i])\n",
        "    print(\"Epoch: \"+ str(lstms1[i].params['epochs']))\n",
        "    print(\"Neurons: \"+str(m.layers[0].units))\n",
        "\n",
        "    i = i+1\n",
        "    ws1['A'+str(i)] = 'DWT-LSTM'\n",
        "    ws1['B'+str(i)] = hyperparam1[i-1][0]\n",
        "    ws1['C'+str(i)] = hyperparam1[i-1][1]\n",
        "    ws1['D'+str(i)] = hyperparam1[i-1][2]\n",
        "    print('RMSE')\n",
        "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
        "    ws1['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAE')\n",
        "    print(Evaluation.mae(inv_y,inv_yhat))\n",
        "    ws1['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAPE')\n",
        "    print(Evaluation.mape(inv_y,inv_yhat))\n",
        "    ws1['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
        "\n",
        "    NeuralNetwork.save_model(m, 1, 'BBCA',hyperparam1[i-1])\n",
        "    with open('DWT_LSTM_BBCA'+str(hyperparam1[i-1])+'.pkl', 'wb') as f:\n",
        "        pickle.dump(lstms1[i-1].history, f)\n",
        "wb1.save('DWT_LSTM_BBCA_result1.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfXLW58XXPYg",
        "outputId": "905afda0-89a2-409b-bcae-c34f474165d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 419ms/step\n",
            "(16, 50, 20)\n",
            "Epoch: 50\n",
            "Neurons: 20\n",
            "RMSE\n",
            "111.93827874079439\n",
            "MAE\n",
            "108.0810546875\n",
            "MAPE\n",
            "1.1142376771907219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 419ms/step\n",
            "(16, 50, 50)\n",
            "Epoch: 50\n",
            "Neurons: 50\n",
            "RMSE\n",
            "61.398595050338294\n",
            "MAE\n",
            "49.31103515625\n",
            "MAPE\n",
            "0.508361187177835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a23161f640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 986ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 100, 20)\n",
            "Epoch: 100\n",
            "Neurons: 20\n",
            "RMSE\n",
            "119.53043782675084\n",
            "MAE\n",
            "114.81640625\n",
            "MAPE\n",
            "1.1836742912371134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x78a23161ff40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 529ms/step\n",
            "(16, 100, 50)\n",
            "Epoch: 100\n",
            "Neurons: 50\n",
            "RMSE\n",
            "92.2848482783593\n",
            "MAE\n",
            "83.41357421875\n",
            "MAPE\n",
            "0.8599337548324741\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lstms2 = []\n",
        "models2 = []\n",
        "for batch, epoch, neuron in hyperparam2:\n",
        "    model, lstm = NeuralNetwork.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
        "    lstms2.append(lstm)\n",
        "    models2.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_2ew6dhZhES",
        "outputId": "7d46d923-dbba-479b-f6c5-af9c344dc86d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "39/39 - 4s - loss: 0.3207 - val_loss: 0.4832 - 4s/epoch - 92ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.0567 - val_loss: 0.0394 - 103ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.1031 - val_loss: 0.0830 - 98ms/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.0565 - val_loss: 0.0205 - 109ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.0518 - val_loss: 0.0142 - 110ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.0271 - val_loss: 0.0150 - 108ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0223 - 110ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0197 - 108ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0184 - 112ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.0140 - val_loss: 0.0167 - 106ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0182 - 117ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0186 - 102ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0168 - 108ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0178 - 112ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0180 - 104ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0177 - 104ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0188 - 109ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0179 - 122ms/epoch - 3ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0174 - 138ms/epoch - 4ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0172 - 110ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0180 - 113ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 108ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0190 - 111ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0194 - 105ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0201 - 103ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0186 - 110ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 116ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 109ms/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0181 - 120ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0176 - 110ms/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0177 - 117ms/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0173 - 108ms/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0170 - 117ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0168 - 109ms/epoch - 3ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0169 - 108ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0156 - 118ms/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0164 - 115ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0193 - 108ms/epoch - 3ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0188 - 112ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0190 - 105ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 112ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0188 - 109ms/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 105ms/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0179 - 109ms/epoch - 3ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 120ms/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0191 - 116ms/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 106ms/epoch - 3ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0183 - 106ms/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0193 - 111ms/epoch - 3ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0186 - 110ms/epoch - 3ms/step\n",
            "Epoch 1/50\n",
            "39/39 - 3s - loss: 0.3297 - val_loss: 0.3909 - 3s/epoch - 64ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.0372 - val_loss: 0.0133 - 108ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.0770 - val_loss: 0.0115 - 107ms/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.0602 - val_loss: 0.0080 - 111ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.0298 - val_loss: 0.0268 - 143ms/epoch - 4ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.0219 - val_loss: 0.0327 - 193ms/epoch - 5ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.0208 - val_loss: 0.0277 - 164ms/epoch - 4ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.0193 - val_loss: 0.0199 - 177ms/epoch - 5ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.0172 - val_loss: 0.0100 - 178ms/epoch - 5ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0068 - 163ms/epoch - 4ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0094 - 178ms/epoch - 5ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0133 - 193ms/epoch - 5ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0168 - 176ms/epoch - 5ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0175 - 174ms/epoch - 4ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0185 - 181ms/epoch - 5ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0162 - 165ms/epoch - 4ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0151 - 157ms/epoch - 4ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0139 - 164ms/epoch - 4ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0126 - 176ms/epoch - 5ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0112 - 194ms/epoch - 5ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0139 - 169ms/epoch - 4ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0128 - 208ms/epoch - 5ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0119 - 192ms/epoch - 5ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0139 - 177ms/epoch - 5ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0133 - 187ms/epoch - 5ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0123 - 188ms/epoch - 5ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0121 - 185ms/epoch - 5ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0125 - 170ms/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0102 - 160ms/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0114 - 186ms/epoch - 5ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0110 - 189ms/epoch - 5ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0082 - 195ms/epoch - 5ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0103 - 193ms/epoch - 5ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0098 - 193ms/epoch - 5ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0116 - 180ms/epoch - 5ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0071 - 215ms/epoch - 6ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0105 - 207ms/epoch - 5ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0111 - 228ms/epoch - 6ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0094 - 178ms/epoch - 5ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0094 - 207ms/epoch - 5ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0090 - 222ms/epoch - 6ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 247ms/epoch - 6ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0059 - 161ms/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0069 - 160ms/epoch - 4ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0088 - 306ms/epoch - 8ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 1s - loss: 0.0155 - val_loss: 0.0091 - 792ms/epoch - 20ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0063 - 419ms/epoch - 11ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0115 - 288ms/epoch - 7ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0109 - 247ms/epoch - 6ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0100 - 280ms/epoch - 7ms/step\n",
            "Epoch 1/100\n",
            "39/39 - 3s - loss: 0.3207 - val_loss: 0.4832 - 3s/epoch - 74ms/step\n",
            "Epoch 2/100\n",
            "39/39 - 0s - loss: 0.0567 - val_loss: 0.0394 - 168ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "39/39 - 0s - loss: 0.1031 - val_loss: 0.0830 - 180ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "39/39 - 0s - loss: 0.0565 - val_loss: 0.0205 - 238ms/epoch - 6ms/step\n",
            "Epoch 5/100\n",
            "39/39 - 0s - loss: 0.0518 - val_loss: 0.0142 - 294ms/epoch - 8ms/step\n",
            "Epoch 6/100\n",
            "39/39 - 0s - loss: 0.0271 - val_loss: 0.0150 - 247ms/epoch - 6ms/step\n",
            "Epoch 7/100\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0223 - 176ms/epoch - 5ms/step\n",
            "Epoch 8/100\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0197 - 110ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0184 - 225ms/epoch - 6ms/step\n",
            "Epoch 10/100\n",
            "39/39 - 0s - loss: 0.0140 - val_loss: 0.0167 - 110ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0182 - 109ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0186 - 143ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0168 - 102ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0178 - 123ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0180 - 162ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0177 - 106ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0188 - 241ms/epoch - 6ms/step\n",
            "Epoch 18/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0179 - 320ms/epoch - 8ms/step\n",
            "Epoch 19/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0174 - 133ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0172 - 210ms/epoch - 5ms/step\n",
            "Epoch 21/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0180 - 111ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 203ms/epoch - 5ms/step\n",
            "Epoch 23/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0190 - 211ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0194 - 114ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0201 - 205ms/epoch - 5ms/step\n",
            "Epoch 26/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0186 - 143ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 214ms/epoch - 5ms/step\n",
            "Epoch 28/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 188ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0181 - 105ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0176 - 198ms/epoch - 5ms/step\n",
            "Epoch 31/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0177 - 372ms/epoch - 10ms/step\n",
            "Epoch 32/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0173 - 277ms/epoch - 7ms/step\n",
            "Epoch 33/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0170 - 305ms/epoch - 8ms/step\n",
            "Epoch 34/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0168 - 142ms/epoch - 4ms/step\n",
            "Epoch 35/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0169 - 278ms/epoch - 7ms/step\n",
            "Epoch 36/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0156 - 345ms/epoch - 9ms/step\n",
            "Epoch 37/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0164 - 152ms/epoch - 4ms/step\n",
            "Epoch 38/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0193 - 216ms/epoch - 6ms/step\n",
            "Epoch 39/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0188 - 209ms/epoch - 5ms/step\n",
            "Epoch 40/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0190 - 149ms/epoch - 4ms/step\n",
            "Epoch 41/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 291ms/epoch - 7ms/step\n",
            "Epoch 42/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0188 - 160ms/epoch - 4ms/step\n",
            "Epoch 43/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 248ms/epoch - 6ms/step\n",
            "Epoch 44/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0179 - 214ms/epoch - 5ms/step\n",
            "Epoch 45/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 270ms/epoch - 7ms/step\n",
            "Epoch 46/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0191 - 379ms/epoch - 10ms/step\n",
            "Epoch 47/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 346ms/epoch - 9ms/step\n",
            "Epoch 48/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0183 - 168ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0193 - 287ms/epoch - 7ms/step\n",
            "Epoch 50/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0186 - 162ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0185 - 123ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 105ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0193 - 222ms/epoch - 6ms/step\n",
            "Epoch 54/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0196 - 109ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0183 - 106ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0186 - 256ms/epoch - 7ms/step\n",
            "Epoch 57/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0188 - 110ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0201 - 148ms/epoch - 4ms/step\n",
            "Epoch 59/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0179 - 258ms/epoch - 7ms/step\n",
            "Epoch 60/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0194 - 455ms/epoch - 12ms/step\n",
            "Epoch 61/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0189 - 370ms/epoch - 9ms/step\n",
            "Epoch 62/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0184 - 241ms/epoch - 6ms/step\n",
            "Epoch 63/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0195 - 280ms/epoch - 7ms/step\n",
            "Epoch 64/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0181 - 223ms/epoch - 6ms/step\n",
            "Epoch 65/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0175 - 181ms/epoch - 5ms/step\n",
            "Epoch 66/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0173 - 134ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0187 - 106ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0196 - 110ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0187 - 107ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0188 - 105ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0179 - 119ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0199 - 112ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0187 - 108ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0197 - 111ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0208 - 106ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0177 - 105ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0179 - 113ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0189 - 107ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0202 - 105ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0192 - 119ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0188 - 106ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0195 - 108ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0190 - 117ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0189 - 112ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0188 - 106ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0194 - 110ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0189 - 106ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0195 - 106ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0182 - 115ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0177 - 107ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0183 - 106ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0173 - 112ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0181 - 102ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0170 - 105ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0182 - 113ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0166 - 102ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0183 - 105ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0181 - 118ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0172 - 107ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0177 - 110ms/epoch - 3ms/step\n",
            "Epoch 1/100\n",
            "39/39 - 2s - loss: 0.3297 - val_loss: 0.3909 - 2s/epoch - 63ms/step\n",
            "Epoch 2/100\n",
            "39/39 - 0s - loss: 0.0372 - val_loss: 0.0133 - 166ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "39/39 - 0s - loss: 0.0770 - val_loss: 0.0115 - 165ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "39/39 - 0s - loss: 0.0602 - val_loss: 0.0080 - 160ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "39/39 - 0s - loss: 0.0298 - val_loss: 0.0268 - 160ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "39/39 - 0s - loss: 0.0219 - val_loss: 0.0327 - 140ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "39/39 - 0s - loss: 0.0208 - val_loss: 0.0277 - 154ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "39/39 - 0s - loss: 0.0193 - val_loss: 0.0199 - 153ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "39/39 - 0s - loss: 0.0172 - val_loss: 0.0100 - 146ms/epoch - 4ms/step\n",
            "Epoch 10/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0068 - 167ms/epoch - 4ms/step\n",
            "Epoch 11/100\n",
            "39/39 - 0s - loss: 0.0139 - val_loss: 0.0094 - 153ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0133 - 160ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0168 - 157ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0175 - 155ms/epoch - 4ms/step\n",
            "Epoch 15/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0185 - 171ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0162 - 160ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0151 - 161ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0139 - 180ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0126 - 176ms/epoch - 5ms/step\n",
            "Epoch 20/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0112 - 156ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0139 - 204ms/epoch - 5ms/step\n",
            "Epoch 22/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0128 - 155ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0119 - 151ms/epoch - 4ms/step\n",
            "Epoch 24/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0139 - 148ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0133 - 151ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0123 - 148ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0121 - 161ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0125 - 189ms/epoch - 5ms/step\n",
            "Epoch 29/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0102 - 146ms/epoch - 4ms/step\n",
            "Epoch 30/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0114 - 174ms/epoch - 4ms/step\n",
            "Epoch 31/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0110 - 132ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0082 - 110ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0103 - 106ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0098 - 108ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0116 - 128ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0071 - 111ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0105 - 116ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0111 - 112ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0094 - 109ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0094 - 109ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0090 - 105ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 108ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0059 - 126ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0069 - 124ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0088 - 110ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0091 - 114ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0063 - 111ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0115 - 111ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0109 - 106ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0100 - 111ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0118 - 115ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0130 - 110ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0147 - 119ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "39/39 - 0s - loss: 0.0163 - val_loss: 0.0160 - 111ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "39/39 - 0s - loss: 0.0163 - val_loss: 0.0143 - 115ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "39/39 - 0s - loss: 0.0162 - val_loss: 0.0155 - 111ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "39/39 - 0s - loss: 0.0163 - val_loss: 0.0153 - 107ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "39/39 - 0s - loss: 0.0162 - val_loss: 0.0170 - 103ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "39/39 - 0s - loss: 0.0161 - val_loss: 0.0161 - 105ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0130 - 115ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0156 - 110ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "39/39 - 0s - loss: 0.0161 - val_loss: 0.0157 - 124ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "39/39 - 0s - loss: 0.0161 - val_loss: 0.0169 - 105ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0174 - 113ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0165 - 109ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0161 - 109ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0155 - 109ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0154 - 108ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0157 - 111ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0154 - 109ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0150 - 116ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0148 - 108ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0151 - 112ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0168 - 108ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0197 - 112ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0176 - 112ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0169 - 112ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0194 - 114ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0162 - 108ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0146 - 125ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0168 - 109ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0212 - 112ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0163 - 108ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0168 - 107ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0186 - 114ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0175 - 107ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0166 - 110ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0183 - 113ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0175 - 116ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0167 - 113ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0173 - 111ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0173 - 105ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0173 - 106ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0161 - 106ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0175 - 107ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0170 - 117ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0177 - 115ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0168 - 121ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0175 - 116ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0171 - 111ms/epoch - 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "wb2 = Workbook()\n",
        "ws2 = wb2.active\n",
        "for m in models2:\n",
        "    # make a prediction\n",
        "    test_x2 = test_X\n",
        "    yhat = m.predict(test_x2)\n",
        "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
        "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
        "    print(hyperparam2[i])\n",
        "    print(\"Epoch: \"+ str(lstms2[i].params['epochs']))\n",
        "    print(\"Neurons: \"+str(m.layers[0].units))\n",
        "\n",
        "    i = i+1\n",
        "    ws2['A'+str(i)] = 'DWT-LSTM'\n",
        "    ws2['B'+str(i)] = hyperparam2[i-1][0]\n",
        "    ws2['C'+str(i)] = hyperparam2[i-1][1]\n",
        "    ws2['D'+str(i)] = hyperparam2[i-1][2]\n",
        "\n",
        "    print('RMSE')\n",
        "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
        "    ws2['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAE')\n",
        "    print(Evaluation.mae(inv_y,inv_yhat))\n",
        "    ws2['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAPE')\n",
        "    print(Evaluation.mape(inv_y,inv_yhat))\n",
        "    ws2['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
        "\n",
        "    NeuralNetwork.save_model(m, 1, 'BBCA',hyperparam2[i-1])\n",
        "    with open('DWT_LSTM_BBCA'+str(hyperparam2[i-1])+'.pkl', 'wb') as f:\n",
        "        pickle.dump(lstms2[i-1].history, f)\n",
        "wb2.save('DWT_LSTM_BBCA_result2.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAbxjbvIfoJW",
        "outputId": "73dac625-ce9d-431a-ba13-17b856518d86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 421ms/step\n",
            "(32, 50, 20)\n",
            "Epoch: 50\n",
            "Neurons: 20\n",
            "RMSE\n",
            "101.28152111738687\n",
            "MAE\n",
            "97.8408203125\n",
            "MAPE\n",
            "1.00866825064433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 425ms/step\n",
            "(32, 50, 50)\n",
            "Epoch: 50\n",
            "Neurons: 50\n",
            "RMSE\n",
            "61.28013353045634\n",
            "MAE\n",
            "52.8916015625\n",
            "MAPE\n",
            "0.5452742429123711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 406ms/step\n",
            "(32, 100, 20)\n",
            "Epoch: 100\n",
            "Neurons: 20\n",
            "RMSE\n",
            "97.71976740264458\n",
            "MAE\n",
            "93.38232421875\n",
            "MAPE\n",
            "0.9627043733891751\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 443ms/step\n",
            "(32, 100, 50)\n",
            "Epoch: 100\n",
            "Neurons: 50\n",
            "RMSE\n",
            "96.00954979842545\n",
            "MAE\n",
            "90.328125\n",
            "MAPE\n",
            "0.9312177835051547\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmZS_wK6u3n9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}