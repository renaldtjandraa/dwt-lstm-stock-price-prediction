{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import Library"
      ],
      "metadata": {
        "id": "QBqp6RZee7aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "1R2-bAfYe66L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a11c6a7f-473e-4fe6-950a-13e08108c382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pandas import read_csv\n",
        "from pandas import DataFrame\n",
        "from pandas import concat\n",
        "\n",
        "from pywt import dwt\n",
        "from pywt import idwt\n",
        "import pywt\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import LSTM, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import initializers\n",
        "\n",
        "from openpyxl.workbook import Workbook\n",
        "import pickle\n",
        "\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Y9n_Gu70Us8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Preprocessing"
      ],
      "metadata": {
        "id": "5UH8lcxMGsIh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Preprocessing:\n",
        "\n",
        "    def minmax_scale(df):\n",
        "        FEATURES = ['Open', 'High', 'Low', 'Volume', 'Close']\n",
        "        scaler = MinMaxScaler()\n",
        "        df_scaled = scaler.fit_transform(np.array(df[FEATURES]))\n",
        "\n",
        "        scaler_pred = MinMaxScaler()\n",
        "        pred_scaled = scaler_pred.fit_transform(np.array(df['Close']).reshape(-1,1))\n",
        "        return df_scaled, scaler_pred\n",
        "\n",
        "    def inverse_scaler(pred, scaler):\n",
        "        pred_inversed = scaler.inverse_transform(pred)\n",
        "        return pred_inversed\n",
        "\n",
        "    def splitting_data(df):\n",
        "        test_size = 3\n",
        "        train_size = len(df)-test_size\n",
        "        train_data,test_data= df[0:train_size,:], df[train_size:len(df),:]\n",
        "        return train_data, test_data\n",
        "\n",
        "\n",
        "    def data_denoising(data,wavelet_type, threshold):\n",
        "        decomposed_data = pd.DataFrame(index=range(len(data)))\n",
        "        for i in range(data.shape[1]):\n",
        "            # Mendekomposisi data menggunakan pywt.dwt\n",
        "            cA, cD = pywt.dwt(data[:, i], wavelet_type)\n",
        "\n",
        "            # Melakukan thresholding pada cD\n",
        "            cD_threshold = pywt.threshold(cD, threshold, mode='soft')\n",
        "\n",
        "            # Menggabungkan cA dan cD_threshold untuk merekonstruksi\n",
        "            reconstructed_data = pywt.idwt(cA, cD_threshold, wavelet_type)\n",
        "\n",
        "            # Menyimpan hasil rekonstruksi ke dalam dataframe hasil\n",
        "            decomposed_data[i] = reconstructed_data\n",
        "\n",
        "        return decomposed_data\n",
        "\n",
        "\n",
        "    def create_dataset(dataset, time_step=1, index=4):\n",
        "        dataX = []\n",
        "        dataY = []\n",
        "\n",
        "        for i in range(len(dataset)-time_step):\n",
        "            dataX.append(dataset[i:(i+time_step)])\n",
        "            dataY.append(float(dataset[i+time_step][index]))\n",
        "        return np.array(dataX), np.array(dataY)\n"
      ],
      "metadata": {
        "id": "NYn3XfonG2Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Model"
      ],
      "metadata": {
        "id": "40ydH8cHGuYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    def train_lstm(train_X, train_y, test_X, test_y, unit, epoch, batch):\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(unit, kernel_initializer=initializers.GlorotUniform(seed=42),\n",
        "                       input_shape=(train_X.shape[1], train_X.shape[2])))\n",
        "        model.add(Dense(units=1, kernel_initializer=initializers.GlorotUniform(seed=42)))\n",
        "        model.compile(loss='mae',optimizer='adam')\n",
        "        history = model.fit(train_X, train_y, epochs=epoch, batch_size=batch,\n",
        "                            validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
        "        return model, history\n",
        "\n",
        "    def save_model(model, category, stocks_name, hyperparam):\n",
        "        if category == 0:\n",
        "            model.save('LSTM_'+ stocks_name +str(hyperparam)+'.h5')\n",
        "        else:\n",
        "            model.save('DWT_LSTM'+ stocks_name +str(hyperparam)+'.h5')"
      ],
      "metadata": {
        "id": "HFFXkgbEG0AP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Evaluation"
      ],
      "metadata": {
        "id": "XatKnp1ZG0b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Evaluation:\n",
        "    def rmse (y, yhat):\n",
        "        differences = [y[i] - yhat[i] for i in range(len(y))]\n",
        "        squared_differences = [d**2 for d in differences]\n",
        "        sum_squared_differences = sum(squared_differences)\n",
        "        mean_squared_error = sum_squared_differences / len(y)\n",
        "        return (mean_squared_error**0.5)[0]\n",
        "\n",
        "    def mae (y, yhat):\n",
        "        differences = [y[i] - yhat[i] for i in range(len(y))]\n",
        "        absolute_differences = [abs(x) for x in differences]\n",
        "        sum_absolute_difference = sum(absolute_differences)\n",
        "        mean_absolute_error = sum_absolute_difference / len(y)\n",
        "        return mean_absolute_error[0]\n",
        "\n",
        "    def mape (y, yhat):\n",
        "        divided_differences = [abs((y[i] - yhat[i])/y[i]) for i in range(len(y))]\n",
        "        sum_absolute_difference = sum(divided_differences)\n",
        "        mean_absolute_percentage_error = sum_absolute_difference / len(y)\n",
        "        return (mean_absolute_percentage_error*100)[0]"
      ],
      "metadata": {
        "id": "OVo5Axa2Hbku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Main"
      ],
      "metadata": {
        "id": "X-07BkzhHk43"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BBCA_dfd= pd.read_csv('/content/drive/MyDrive/Data/BBCA.JK.csv')\n",
        "BBCA_dfd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "b-XUtuCm_j_1",
        "outputId": "c7780636-d42a-458f-e693-91272ac611a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Date    Open    High     Low   Close    Adj Close     Volume\n",
              "0     2019-01-16  5260.0  5285.0  5245.0  5285.0  4813.968262   94972500\n",
              "1     2019-01-17  5290.0  5330.0  5285.0  5330.0  4854.957520   91654000\n",
              "2     2019-01-18  5340.0  5425.0  5315.0  5425.0  4941.490234  100873500\n",
              "3     2019-01-21  5425.0  5600.0  5390.0  5545.0  5050.795410   87118000\n",
              "4     2019-01-22  5600.0  5620.0  5450.0  5600.0  5100.893066   91907000\n",
              "...          ...     ...     ...     ...     ...          ...        ...\n",
              "1226  2024-01-09  9600.0  9625.0  9575.0  9625.0  9625.000000   59848600\n",
              "1227  2024-01-10  9650.0  9650.0  9550.0  9550.0  9550.000000   52774900\n",
              "1228  2024-01-11  9625.0  9650.0  9575.0  9575.0  9575.000000   39381500\n",
              "1229  2024-01-12  9650.0  9700.0  9600.0  9700.0  9700.000000   68253400\n",
              "1230  2024-01-15  9700.0  9700.0  9700.0  9700.0  9700.000000          0\n",
              "\n",
              "[1231 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f8757b37-565e-4785-8763-e7afb6323fb5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-01-16</td>\n",
              "      <td>5260.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>5245.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>4813.968262</td>\n",
              "      <td>94972500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>5290.0</td>\n",
              "      <td>5330.0</td>\n",
              "      <td>5285.0</td>\n",
              "      <td>5330.0</td>\n",
              "      <td>4854.957520</td>\n",
              "      <td>91654000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>5340.0</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>5315.0</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>4941.490234</td>\n",
              "      <td>100873500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2019-01-21</td>\n",
              "      <td>5425.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5390.0</td>\n",
              "      <td>5545.0</td>\n",
              "      <td>5050.795410</td>\n",
              "      <td>87118000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2019-01-22</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5620.0</td>\n",
              "      <td>5450.0</td>\n",
              "      <td>5600.0</td>\n",
              "      <td>5100.893066</td>\n",
              "      <td>91907000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1226</th>\n",
              "      <td>2024-01-09</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9625.000000</td>\n",
              "      <td>59848600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1227</th>\n",
              "      <td>2024-01-10</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9550.0</td>\n",
              "      <td>9550.0</td>\n",
              "      <td>9550.000000</td>\n",
              "      <td>52774900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1228</th>\n",
              "      <td>2024-01-11</td>\n",
              "      <td>9625.0</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9575.0</td>\n",
              "      <td>9575.000000</td>\n",
              "      <td>39381500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1229</th>\n",
              "      <td>2024-01-12</td>\n",
              "      <td>9650.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9600.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.000000</td>\n",
              "      <td>68253400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>2024-01-15</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.0</td>\n",
              "      <td>9700.000000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1231 rows Ã— 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8757b37-565e-4785-8763-e7afb6323fb5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8757b37-565e-4785-8763-e7afb6323fb5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8757b37-565e-4785-8763-e7afb6323fb5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f67986a7-57a7-4501-8f67-eddae8b8a777\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f67986a7-57a7-4501-8f67-eddae8b8a777')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f67986a7-57a7-4501-8f67-eddae8b8a777 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "BBCA_dfd",
              "summary": "{\n  \"name\": \"BBCA_dfd\",\n  \"rows\": 1231,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1231,\n        \"samples\": [\n          \"2021-03-31\",\n          \"2023-04-12\",\n          \"2019-12-26\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1263.1991404297676,\n        \"min\": 4450.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 384,\n        \"samples\": [\n          6555.0,\n          6850.0,\n          8975.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"High\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1266.5980246818408,\n        \"min\": 4800.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 385,\n        \"samples\": [\n          6665.0,\n          7300.0,\n          8825.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1266.5402526803089,\n        \"min\": 4325.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 386,\n        \"samples\": [\n          8500.0,\n          7650.0,\n          6015.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1267.9580245002148,\n        \"min\": 4430.0,\n        \"max\": 9700.0,\n        \"num_unique_values\": 392,\n        \"samples\": [\n          6040.0,\n          6225.0,\n          7160.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Adj Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1394.7166833799854,\n        \"min\": 4084.944092,\n        \"max\": 9700.0,\n        \"num_unique_values\": 636,\n        \"samples\": [\n          5262.461426,\n          9475.0,\n          5551.970703\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 54463534,\n        \"min\": 0,\n        \"max\": 722827900,\n        \"num_unique_values\": 1214,\n        \"samples\": [\n          71945100,\n          62776200,\n          51527000\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Normalization"
      ],
      "metadata": {
        "id": "9d62VNJKMLA9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x,scaler = Preprocessing.minmax_scale(BBCA_dfd)"
      ],
      "metadata": {
        "id": "TqYLczYjAG3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Data kelima fitur yang dinormalisasi : ')\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxI5cdFnAHDb",
        "outputId": "b415be8d-9995-4cfd-ea4b-c584d0ba5eba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data kelima fitur yang dinormalisasi : \n",
            "[[0.15428571 0.09897959 0.17116279 0.1313902  0.16223909]\n",
            " [0.16       0.10816327 0.17860465 0.1267992  0.17077799]\n",
            " [0.16952381 0.12755102 0.18418605 0.13955397 0.18880455]\n",
            " ...\n",
            " [0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]\n",
            " [0.99047619 1.         0.98139535 0.09442552 1.        ]\n",
            " [1.         1.         1.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "hsAGVc1HMSc6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train,test = Preprocessing.splitting_data(x)"
      ],
      "metadata": {
        "id": "AuSQcElO00LR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training Data :\")\n",
        "print(train)\n",
        "print(\"=========================================================\")\n",
        "print(\"Testing Data :\")\n",
        "print(test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTgV6TvfLbIT",
        "outputId": "ad9d6d56-a4f8-48c3-baff-54506e8bf691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data :\n",
            "[[0.15428571 0.09897959 0.17116279 0.1313902  0.16223909]\n",
            " [0.16       0.10816327 0.17860465 0.1267992  0.17077799]\n",
            " [0.16952381 0.12755102 0.18418605 0.13955397 0.18880455]\n",
            " ...\n",
            " [0.98095238 0.98469388 0.95813953 0.07041233 0.97628083]\n",
            " [0.98095238 0.98469388 0.97674419 0.08279786 0.9857685 ]\n",
            " [0.99047619 0.98979592 0.97209302 0.07301171 0.971537  ]]\n",
            "=========================================================\n",
            "Testing Data :\n",
            "[[0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]\n",
            " [0.99047619 1.         0.98139535 0.09442552 1.        ]\n",
            " [1.         1.         1.         0.         1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Denoising"
      ],
      "metadata": {
        "id": "ZIf2smd2Ngr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.004\n",
        "wavelet_type = 'db4'\n",
        "\n",
        "denoised_train = Preprocessing.data_denoising(train,wavelet_type,threshold)"
      ],
      "metadata": {
        "id": "7kHHfsM0M1WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hasil data training yang telah bersih dari noise \")\n",
        "print(denoised_train.values)\n",
        "print(len(denoised_train.values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KusC9tiGOW3V",
        "outputId": "d0639f63-20e8-4680-b22e-db9cbebfc009"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hasil data training yang telah bersih dari noise \n",
            "[[0.15444091 0.09757096 0.17128001 0.12973099 0.16079503]\n",
            " [0.15862625 0.10828911 0.17682462 0.12971233 0.17124551]\n",
            " [0.1702379  0.12866194 0.18587945 0.13665826 0.18818151]\n",
            " ...\n",
            " [0.97914184 0.98283911 0.96196319 0.07401206 0.97992598]\n",
            " [0.98369689 0.98749579 0.97389351 0.07997662 0.98296119]\n",
            " [0.98982205 0.98944009 0.97192297 0.07358438 0.97202076]]\n",
            "1228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating Dataset"
      ],
      "metadata": {
        "id": "8RoDl3dNS8w-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, train_y = Preprocessing.create_dataset(denoised_train.values)\n",
        "test_X, test_y = Preprocessing.create_dataset(test)"
      ],
      "metadata": {
        "id": "lSzRoqZ8PhMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data train_X\")\n",
        "print(\"=====================================\")\n",
        "print(train_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rlqpujilR0xA",
        "outputId": "0bdb7a65-3f57-4c6f-8d0a-a1f187e2046a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train_X\n",
            "=====================================\n",
            "[[[0.15444091 0.09757096 0.17128001 0.12973099 0.16079503]]\n",
            "\n",
            " [[0.15862625 0.10828911 0.17682462 0.12971233 0.17124551]]\n",
            "\n",
            " [[0.1702379  0.12866194 0.18587945 0.13665826 0.18818151]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.95891976 0.9765894  0.95543382 0.11525239 0.97354568]]\n",
            "\n",
            " [[0.97914184 0.98283911 0.96196319 0.07401206 0.97992598]]\n",
            "\n",
            " [[0.98369689 0.98749579 0.97389351 0.07997662 0.98296119]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data train_y\")\n",
        "print(\"=====================================\")\n",
        "print(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhBdjYFoTknR",
        "outputId": "ddd76d91-94dd-4410-df6d-c3a9a697a14d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data train_y\n",
            "=====================================\n",
            "[0.17124551 0.18818151 0.21426186 ... 0.97992598 0.98296119 0.97202076]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data test_X\")\n",
        "print(\"=====================================\")\n",
        "print(test_X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR7SG6s3T1rO",
        "outputId": "06184215-732e-47c0-dca0-eb87a41b9920"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data test_X\n",
            "=====================================\n",
            "[[[0.98571429 0.98979592 0.97674419 0.05448254 0.97628083]]\n",
            "\n",
            " [[0.99047619 1.         0.98139535 0.09442552 1.        ]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data test_y\")\n",
        "print(\"=====================================\")\n",
        "print(test_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q14XzOx_UanI",
        "outputId": "73bfc35f-a40c-47de-a885-8b77fd95c72c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data test_y\n",
            "=====================================\n",
            "[1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Hyperparameter Combination"
      ],
      "metadata": {
        "id": "v9lceIehU5ME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = []\n",
        "batch = [16, 32]\n",
        "epoch = [50, 100]\n",
        "neuron = [20,50]\n",
        "for j in batch:\n",
        "    for k in epoch:\n",
        "        for l in neuron:\n",
        "            hyperparams.append((j,k,l))\n",
        "hyperparams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMpZ4ISZUgOr",
        "outputId": "2e8a78af-def4-46a0-c1e2-dacd8a3c466d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 50, 20),\n",
              " (16, 50, 50),\n",
              " (16, 100, 20),\n",
              " (16, 100, 50),\n",
              " (32, 50, 20),\n",
              " (32, 50, 50),\n",
              " (32, 100, 20),\n",
              " (32, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam1 = hyperparams[:4]\n",
        "hyperparam2 = hyperparams[4:8]\n",
        "hyperparam1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g90mOo39VmvE",
        "outputId": "a545a388-75f3-4ae2-900c-89e925087e8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(16, 50, 20), (16, 50, 50), (16, 100, 20), (16, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUlU0nSDWJvz",
        "outputId": "f7fc1175-e84e-42b3-84d6-43cb76322907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(32, 50, 20), (32, 50, 50), (32, 100, 20), (32, 100, 50)]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Model"
      ],
      "metadata": {
        "id": "IAogp9HYXKIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstms1 = []\n",
        "models1 = []\n",
        "for batch, epoch, neuron in hyperparam1:\n",
        "    model, lstm = NeuralNetwork.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
        "    lstms1.append(lstm)\n",
        "    models1.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_DX2E7FWLrd",
        "outputId": "9775c484-707f-42d2-a222-6baf4b2028a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "77/77 - 4s - loss: 0.1455 - val_loss: 0.0142 - 4s/epoch - 51ms/step\n",
            "Epoch 2/50\n",
            "77/77 - 0s - loss: 0.0517 - val_loss: 0.0456 - 185ms/epoch - 2ms/step\n",
            "Epoch 3/50\n",
            "77/77 - 0s - loss: 0.0403 - val_loss: 0.0274 - 184ms/epoch - 2ms/step\n",
            "Epoch 4/50\n",
            "77/77 - 0s - loss: 0.0314 - val_loss: 0.0220 - 182ms/epoch - 2ms/step\n",
            "Epoch 5/50\n",
            "77/77 - 0s - loss: 0.0228 - val_loss: 0.0251 - 186ms/epoch - 2ms/step\n",
            "Epoch 6/50\n",
            "77/77 - 0s - loss: 0.0183 - val_loss: 0.0274 - 207ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "77/77 - 0s - loss: 0.0154 - val_loss: 0.0212 - 189ms/epoch - 2ms/step\n",
            "Epoch 8/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0188 - 194ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0202 - 182ms/epoch - 2ms/step\n",
            "Epoch 10/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0176 - 193ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0180 - 206ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0175 - 199ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0173 - 189ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0190 - 194ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0175 - 187ms/epoch - 2ms/step\n",
            "Epoch 16/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0183 - 176ms/epoch - 2ms/step\n",
            "Epoch 17/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0178 - 195ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0194 - 186ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0197 - 179ms/epoch - 2ms/step\n",
            "Epoch 20/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0189 - 207ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0191 - 185ms/epoch - 2ms/step\n",
            "Epoch 22/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0187 - 189ms/epoch - 2ms/step\n",
            "Epoch 23/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0189 - 180ms/epoch - 2ms/step\n",
            "Epoch 24/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0192 - 179ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0195 - 185ms/epoch - 2ms/step\n",
            "Epoch 26/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0198 - 184ms/epoch - 2ms/step\n",
            "Epoch 27/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 201ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 191ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0184 - 177ms/epoch - 2ms/step\n",
            "Epoch 30/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 174ms/epoch - 2ms/step\n",
            "Epoch 31/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0199 - 183ms/epoch - 2ms/step\n",
            "Epoch 32/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0199 - 181ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0194 - 201ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 179ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 176ms/epoch - 2ms/step\n",
            "Epoch 36/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0191 - 186ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0183 - 177ms/epoch - 2ms/step\n",
            "Epoch 38/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0193 - 182ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0193 - 196ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0194 - 188ms/epoch - 2ms/step\n",
            "Epoch 41/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0180 - 177ms/epoch - 2ms/step\n",
            "Epoch 42/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0192 - 179ms/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 184ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0211 - 184ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0187 - 181ms/epoch - 2ms/step\n",
            "Epoch 46/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0181 - 190ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0188 - 179ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0188 - 180ms/epoch - 2ms/step\n",
            "Epoch 49/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0190 - 181ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0180 - 194ms/epoch - 3ms/step\n",
            "Epoch 1/50\n",
            "77/77 - 4s - loss: 0.1186 - val_loss: 0.0423 - 4s/epoch - 51ms/step\n",
            "Epoch 2/50\n",
            "77/77 - 0s - loss: 0.0477 - val_loss: 0.0358 - 306ms/epoch - 4ms/step\n",
            "Epoch 3/50\n",
            "77/77 - 0s - loss: 0.0371 - val_loss: 0.0354 - 313ms/epoch - 4ms/step\n",
            "Epoch 4/50\n",
            "77/77 - 0s - loss: 0.0279 - val_loss: 0.0246 - 204ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "77/77 - 0s - loss: 0.0228 - val_loss: 0.0158 - 208ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "77/77 - 0s - loss: 0.0177 - val_loss: 0.0074 - 197ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "77/77 - 0s - loss: 0.0151 - val_loss: 0.0062 - 194ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0061 - 188ms/epoch - 2ms/step\n",
            "Epoch 9/50\n",
            "77/77 - 0s - loss: 0.0147 - val_loss: 0.0083 - 194ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0064 - 205ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 204ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0063 - 202ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0064 - 189ms/epoch - 2ms/step\n",
            "Epoch 14/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 190ms/epoch - 2ms/step\n",
            "Epoch 15/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 210ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0065 - 195ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 204ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 191ms/epoch - 2ms/step\n",
            "Epoch 19/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0066 - 194ms/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 209ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0066 - 204ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 198ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "77/77 - 0s - loss: 0.0147 - val_loss: 0.0066 - 199ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 191ms/epoch - 2ms/step\n",
            "Epoch 25/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 242ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0074 - 232ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0073 - 193ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0067 - 191ms/epoch - 2ms/step\n",
            "Epoch 29/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0082 - 234ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0081 - 204ms/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 208ms/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0077 - 191ms/epoch - 2ms/step\n",
            "Epoch 33/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0087 - 184ms/epoch - 2ms/step\n",
            "Epoch 34/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0094 - 179ms/epoch - 2ms/step\n",
            "Epoch 35/50\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0099 - 197ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0098 - 183ms/epoch - 2ms/step\n",
            "Epoch 37/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0081 - 202ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0083 - 189ms/epoch - 2ms/step\n",
            "Epoch 39/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 186ms/epoch - 2ms/step\n",
            "Epoch 40/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0099 - 215ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0100 - 198ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0069 - 186ms/epoch - 2ms/step\n",
            "Epoch 43/50\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0091 - 191ms/epoch - 2ms/step\n",
            "Epoch 44/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0070 - 181ms/epoch - 2ms/step\n",
            "Epoch 45/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0099 - 201ms/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0098 - 191ms/epoch - 2ms/step\n",
            "Epoch 47/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0095 - 188ms/epoch - 2ms/step\n",
            "Epoch 48/50\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0095 - 194ms/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0108 - 185ms/epoch - 2ms/step\n",
            "Epoch 50/50\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0112 - 189ms/epoch - 2ms/step\n",
            "Epoch 1/100\n",
            "77/77 - 4s - loss: 0.1455 - val_loss: 0.0142 - 4s/epoch - 51ms/step\n",
            "Epoch 2/100\n",
            "77/77 - 0s - loss: 0.0517 - val_loss: 0.0456 - 286ms/epoch - 4ms/step\n",
            "Epoch 3/100\n",
            "77/77 - 0s - loss: 0.0403 - val_loss: 0.0274 - 294ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "77/77 - 0s - loss: 0.0314 - val_loss: 0.0220 - 290ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "77/77 - 0s - loss: 0.0228 - val_loss: 0.0251 - 243ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "77/77 - 0s - loss: 0.0183 - val_loss: 0.0274 - 193ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "77/77 - 0s - loss: 0.0154 - val_loss: 0.0212 - 178ms/epoch - 2ms/step\n",
            "Epoch 8/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0188 - 184ms/epoch - 2ms/step\n",
            "Epoch 9/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0202 - 194ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0176 - 195ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0180 - 186ms/epoch - 2ms/step\n",
            "Epoch 12/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0175 - 180ms/epoch - 2ms/step\n",
            "Epoch 13/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0173 - 182ms/epoch - 2ms/step\n",
            "Epoch 14/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0190 - 191ms/epoch - 2ms/step\n",
            "Epoch 15/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0175 - 187ms/epoch - 2ms/step\n",
            "Epoch 16/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0183 - 198ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0178 - 181ms/epoch - 2ms/step\n",
            "Epoch 18/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0194 - 177ms/epoch - 2ms/step\n",
            "Epoch 19/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0197 - 180ms/epoch - 2ms/step\n",
            "Epoch 20/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0189 - 186ms/epoch - 2ms/step\n",
            "Epoch 21/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0191 - 196ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0187 - 185ms/epoch - 2ms/step\n",
            "Epoch 23/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0189 - 177ms/epoch - 2ms/step\n",
            "Epoch 24/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0192 - 192ms/epoch - 2ms/step\n",
            "Epoch 25/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0195 - 181ms/epoch - 2ms/step\n",
            "Epoch 26/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0198 - 181ms/epoch - 2ms/step\n",
            "Epoch 27/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 197ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 174ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0184 - 197ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 182ms/epoch - 2ms/step\n",
            "Epoch 31/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0199 - 188ms/epoch - 2ms/step\n",
            "Epoch 32/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0199 - 192ms/epoch - 2ms/step\n",
            "Epoch 33/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0194 - 191ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 185ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0196 - 182ms/epoch - 2ms/step\n",
            "Epoch 36/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0191 - 188ms/epoch - 2ms/step\n",
            "Epoch 37/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0183 - 212ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0193 - 190ms/epoch - 2ms/step\n",
            "Epoch 39/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0193 - 184ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0194 - 192ms/epoch - 2ms/step\n",
            "Epoch 41/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0180 - 194ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0192 - 184ms/epoch - 2ms/step\n",
            "Epoch 43/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0186 - 197ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0211 - 182ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0187 - 189ms/epoch - 2ms/step\n",
            "Epoch 46/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0181 - 187ms/epoch - 2ms/step\n",
            "Epoch 47/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0188 - 198ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0188 - 309ms/epoch - 4ms/step\n",
            "Epoch 49/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0190 - 268ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0180 - 298ms/epoch - 4ms/step\n",
            "Epoch 51/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0179 - 279ms/epoch - 4ms/step\n",
            "Epoch 52/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0188 - 258ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0185 - 268ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0186 - 309ms/epoch - 4ms/step\n",
            "Epoch 55/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0187 - 375ms/epoch - 5ms/step\n",
            "Epoch 56/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0187 - 348ms/epoch - 5ms/step\n",
            "Epoch 57/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0189 - 337ms/epoch - 4ms/step\n",
            "Epoch 58/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0191 - 361ms/epoch - 5ms/step\n",
            "Epoch 59/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0196 - 318ms/epoch - 4ms/step\n",
            "Epoch 60/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0192 - 330ms/epoch - 4ms/step\n",
            "Epoch 61/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0186 - 299ms/epoch - 4ms/step\n",
            "Epoch 62/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0182 - 324ms/epoch - 4ms/step\n",
            "Epoch 63/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0185 - 345ms/epoch - 4ms/step\n",
            "Epoch 64/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0196 - 312ms/epoch - 4ms/step\n",
            "Epoch 65/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0186 - 343ms/epoch - 4ms/step\n",
            "Epoch 66/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0185 - 363ms/epoch - 5ms/step\n",
            "Epoch 67/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0180 - 275ms/epoch - 4ms/step\n",
            "Epoch 68/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0178 - 361ms/epoch - 5ms/step\n",
            "Epoch 69/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0174 - 381ms/epoch - 5ms/step\n",
            "Epoch 70/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0177 - 284ms/epoch - 4ms/step\n",
            "Epoch 71/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0187 - 293ms/epoch - 4ms/step\n",
            "Epoch 72/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0182 - 298ms/epoch - 4ms/step\n",
            "Epoch 73/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0181 - 322ms/epoch - 4ms/step\n",
            "Epoch 74/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0174 - 307ms/epoch - 4ms/step\n",
            "Epoch 75/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0184 - 205ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0189 - 206ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0188 - 201ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0181 - 178ms/epoch - 2ms/step\n",
            "Epoch 79/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0182 - 201ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0209 - 190ms/epoch - 2ms/step\n",
            "Epoch 81/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0192 - 180ms/epoch - 2ms/step\n",
            "Epoch 82/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0185 - 187ms/epoch - 2ms/step\n",
            "Epoch 83/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0197 - 182ms/epoch - 2ms/step\n",
            "Epoch 84/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0180 - 193ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0199 - 204ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0188 - 192ms/epoch - 2ms/step\n",
            "Epoch 87/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0194 - 187ms/epoch - 2ms/step\n",
            "Epoch 88/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0187 - 174ms/epoch - 2ms/step\n",
            "Epoch 89/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0180 - 179ms/epoch - 2ms/step\n",
            "Epoch 90/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0173 - 192ms/epoch - 2ms/step\n",
            "Epoch 91/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0178 - 187ms/epoch - 2ms/step\n",
            "Epoch 92/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0178 - 191ms/epoch - 2ms/step\n",
            "Epoch 93/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0190 - 183ms/epoch - 2ms/step\n",
            "Epoch 94/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0186 - 184ms/epoch - 2ms/step\n",
            "Epoch 95/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0194 - 181ms/epoch - 2ms/step\n",
            "Epoch 96/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0174 - 201ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0186 - 186ms/epoch - 2ms/step\n",
            "Epoch 98/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0176 - 180ms/epoch - 2ms/step\n",
            "Epoch 99/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0194 - 174ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0186 - 181ms/epoch - 2ms/step\n",
            "Epoch 1/100\n",
            "77/77 - 3s - loss: 0.1186 - val_loss: 0.0423 - 3s/epoch - 34ms/step\n",
            "Epoch 2/100\n",
            "77/77 - 0s - loss: 0.0477 - val_loss: 0.0358 - 182ms/epoch - 2ms/step\n",
            "Epoch 3/100\n",
            "77/77 - 0s - loss: 0.0371 - val_loss: 0.0354 - 207ms/epoch - 3ms/step\n",
            "Epoch 4/100\n",
            "77/77 - 0s - loss: 0.0279 - val_loss: 0.0246 - 198ms/epoch - 3ms/step\n",
            "Epoch 5/100\n",
            "77/77 - 0s - loss: 0.0228 - val_loss: 0.0158 - 199ms/epoch - 3ms/step\n",
            "Epoch 6/100\n",
            "77/77 - 0s - loss: 0.0177 - val_loss: 0.0074 - 195ms/epoch - 3ms/step\n",
            "Epoch 7/100\n",
            "77/77 - 0s - loss: 0.0151 - val_loss: 0.0062 - 200ms/epoch - 3ms/step\n",
            "Epoch 8/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0061 - 215ms/epoch - 3ms/step\n",
            "Epoch 9/100\n",
            "77/77 - 0s - loss: 0.0147 - val_loss: 0.0083 - 195ms/epoch - 3ms/step\n",
            "Epoch 10/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0064 - 189ms/epoch - 2ms/step\n",
            "Epoch 11/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 197ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0063 - 316ms/epoch - 4ms/step\n",
            "Epoch 13/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0064 - 275ms/epoch - 4ms/step\n",
            "Epoch 14/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0064 - 262ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0064 - 259ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0065 - 310ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 283ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0065 - 283ms/epoch - 4ms/step\n",
            "Epoch 19/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0066 - 274ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 277ms/epoch - 4ms/step\n",
            "Epoch 21/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0066 - 289ms/epoch - 4ms/step\n",
            "Epoch 22/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0066 - 280ms/epoch - 4ms/step\n",
            "Epoch 23/100\n",
            "77/77 - 0s - loss: 0.0147 - val_loss: 0.0066 - 366ms/epoch - 5ms/step\n",
            "Epoch 24/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 282ms/epoch - 4ms/step\n",
            "Epoch 25/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0067 - 309ms/epoch - 4ms/step\n",
            "Epoch 26/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0074 - 321ms/epoch - 4ms/step\n",
            "Epoch 27/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0073 - 295ms/epoch - 4ms/step\n",
            "Epoch 28/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0067 - 192ms/epoch - 2ms/step\n",
            "Epoch 29/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0082 - 197ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0081 - 199ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0067 - 197ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "77/77 - 0s - loss: 0.0146 - val_loss: 0.0077 - 205ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0087 - 189ms/epoch - 2ms/step\n",
            "Epoch 34/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0094 - 190ms/epoch - 2ms/step\n",
            "Epoch 35/100\n",
            "77/77 - 0s - loss: 0.0145 - val_loss: 0.0099 - 196ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0098 - 203ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0081 - 194ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "77/77 - 0s - loss: 0.0143 - val_loss: 0.0083 - 199ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0069 - 186ms/epoch - 2ms/step\n",
            "Epoch 40/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0099 - 199ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0100 - 200ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0069 - 200ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "77/77 - 0s - loss: 0.0144 - val_loss: 0.0091 - 209ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0070 - 187ms/epoch - 2ms/step\n",
            "Epoch 45/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0099 - 197ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0098 - 196ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0095 - 194ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0095 - 202ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0108 - 193ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0112 - 235ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0094 - 197ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0115 - 201ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0101 - 193ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0092 - 193ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0138 - 191ms/epoch - 2ms/step\n",
            "Epoch 56/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0071 - 192ms/epoch - 2ms/step\n",
            "Epoch 57/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0113 - 192ms/epoch - 2ms/step\n",
            "Epoch 58/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0085 - 197ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0112 - 193ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0097 - 196ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0096 - 187ms/epoch - 2ms/step\n",
            "Epoch 62/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0090 - 194ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0125 - 204ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0089 - 189ms/epoch - 2ms/step\n",
            "Epoch 65/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0101 - 200ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0120 - 190ms/epoch - 2ms/step\n",
            "Epoch 67/100\n",
            "77/77 - 0s - loss: 0.0140 - val_loss: 0.0129 - 191ms/epoch - 2ms/step\n",
            "Epoch 68/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0099 - 206ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0087 - 203ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0091 - 207ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0074 - 212ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0119 - 201ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0080 - 218ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "77/77 - 0s - loss: 0.0142 - val_loss: 0.0107 - 204ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0105 - 202ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0093 - 195ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0085 - 238ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0088 - 284ms/epoch - 4ms/step\n",
            "Epoch 79/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0111 - 292ms/epoch - 4ms/step\n",
            "Epoch 80/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0076 - 289ms/epoch - 4ms/step\n",
            "Epoch 81/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0108 - 322ms/epoch - 4ms/step\n",
            "Epoch 82/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0113 - 292ms/epoch - 4ms/step\n",
            "Epoch 83/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0075 - 296ms/epoch - 4ms/step\n",
            "Epoch 84/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0121 - 271ms/epoch - 4ms/step\n",
            "Epoch 85/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0075 - 285ms/epoch - 4ms/step\n",
            "Epoch 86/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0136 - 314ms/epoch - 4ms/step\n",
            "Epoch 87/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0094 - 326ms/epoch - 4ms/step\n",
            "Epoch 88/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0076 - 327ms/epoch - 4ms/step\n",
            "Epoch 89/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0076 - 298ms/epoch - 4ms/step\n",
            "Epoch 90/100\n",
            "77/77 - 0s - loss: 0.0141 - val_loss: 0.0154 - 280ms/epoch - 4ms/step\n",
            "Epoch 91/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0076 - 293ms/epoch - 4ms/step\n",
            "Epoch 92/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0076 - 345ms/epoch - 4ms/step\n",
            "Epoch 93/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0076 - 255ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "77/77 - 0s - loss: 0.0139 - val_loss: 0.0140 - 199ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0077 - 196ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0110 - 216ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "77/77 - 0s - loss: 0.0136 - val_loss: 0.0077 - 202ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0077 - 199ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "77/77 - 0s - loss: 0.0137 - val_loss: 0.0077 - 188ms/epoch - 2ms/step\n",
            "Epoch 100/100\n",
            "77/77 - 0s - loss: 0.0138 - val_loss: 0.0142 - 189ms/epoch - 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Model"
      ],
      "metadata": {
        "id": "4qRW8VgDZYmC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "wb1 = Workbook()\n",
        "ws1 = wb1.active\n",
        "for m in models1:\n",
        "    # make a prediction\n",
        "    test_x2 = test_X\n",
        "    yhat = m.predict(test_x2)\n",
        "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
        "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
        "    print(hyperparam1[i])\n",
        "    print(\"Epoch: \"+ str(lstms1[i].params['epochs']))\n",
        "    print(\"Neurons: \"+str(m.layers[0].units))\n",
        "\n",
        "    i = i+1\n",
        "    ws1['A'+str(i)] = 'DWT-LSTM'\n",
        "    ws1['B'+str(i)] = hyperparam1[i-1][0]\n",
        "    ws1['C'+str(i)] = hyperparam1[i-1][1]\n",
        "    ws1['D'+str(i)] = hyperparam1[i-1][2]\n",
        "    print('RMSE')\n",
        "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
        "    ws1['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAE')\n",
        "    print(Evaluation.mae(inv_y,inv_yhat))\n",
        "    ws1['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAPE')\n",
        "    print(Evaluation.mape(inv_y,inv_yhat))\n",
        "    ws1['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
        "\n",
        "    NeuralNetwork.save_model(m, 1, 'BBCA',hyperparam1[i-1])\n",
        "    with open('DWT_LSTM_BBCA'+str(hyperparam1[i-1])+'.pkl', 'wb') as f:\n",
        "        pickle.dump(lstms1[i-1].history, f)\n",
        "wb1.save('DWT_LSTM_BBCA_result1.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EfXLW58XXPYg",
        "outputId": "d0a027c9-f5c0-422c-8b4f-57194a043071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 891ms/step\n",
            "(16, 50, 20)\n",
            "Epoch: 50\n",
            "Neurons: 20\n",
            "RMSE\n",
            "99.60382795379331\n",
            "MAE\n",
            "94.90185546875\n",
            "MAPE\n",
            "0.978369644007732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 440ms/step\n",
            "(16, 50, 50)\n",
            "Epoch: 50\n",
            "Neurons: 50\n",
            "RMSE\n",
            "69.63637561427886\n",
            "MAE\n",
            "59.20703125\n",
            "MAPE\n",
            "0.6103817654639175\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 429ms/step\n",
            "(16, 100, 20)\n",
            "Epoch: 100\n",
            "Neurons: 20\n",
            "RMSE\n",
            "104.38477760476897\n",
            "MAE\n",
            "98.09423828125\n",
            "MAPE\n",
            "1.0112808070231958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7e8961b53640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 428ms/step\n",
            "(16, 100, 50)\n",
            "Epoch: 100\n",
            "Neurons: 50\n",
            "RMSE\n",
            "85.21420857911701\n",
            "MAE\n",
            "75.0751953125\n",
            "MAPE\n",
            "0.7739710856958762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lstms2 = []\n",
        "models2 = []\n",
        "for batch, epoch, neuron in hyperparam2:\n",
        "    model, lstm = NeuralNetwork.train_lstm(train_X, train_y, test_X, test_y, neuron, epoch, batch)\n",
        "    lstms2.append(lstm)\n",
        "    models2.append(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_2ew6dhZhES",
        "outputId": "605d1f88-1471-4342-ee4d-b9f04b9a8e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "39/39 - 3s - loss: 0.3207 - val_loss: 0.4832 - 3s/epoch - 66ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.0566 - val_loss: 0.0392 - 100ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.1034 - val_loss: 0.0838 - 105ms/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.0561 - val_loss: 0.0201 - 113ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.0513 - val_loss: 0.0137 - 113ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.0272 - val_loss: 0.0145 - 113ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0209 - 115ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0204 - 133ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0187 - 113ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0166 - 105ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0176 - 114ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0168 - 116ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0167 - 121ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0154 - 110ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0163 - 123ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0193 - 124ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0203 - 130ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0208 - 118ms/epoch - 3ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0203 - 116ms/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0214 - 121ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0215 - 116ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0219 - 109ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0208 - 108ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0207 - 120ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0206 - 139ms/epoch - 4ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0205 - 113ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0207 - 160ms/epoch - 4ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0207 - 161ms/epoch - 4ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0199 - 146ms/epoch - 4ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0201 - 157ms/epoch - 4ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0193 - 162ms/epoch - 4ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0182 - 167ms/epoch - 4ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0177 - 145ms/epoch - 4ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0180 - 143ms/epoch - 4ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0180 - 151ms/epoch - 4ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 154ms/epoch - 4ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0190 - 174ms/epoch - 4ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0208 - 175ms/epoch - 4ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0203 - 155ms/epoch - 4ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0180 - 149ms/epoch - 4ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0171 - 154ms/epoch - 4ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0186 - 144ms/epoch - 4ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0183 - 170ms/epoch - 4ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0205 - 177ms/epoch - 5ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0199 - 192ms/epoch - 5ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0215 - 148ms/epoch - 4ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0195 - 163ms/epoch - 4ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0209 - 162ms/epoch - 4ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0182 - 156ms/epoch - 4ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0204 - 173ms/epoch - 4ms/step\n",
            "Epoch 1/50\n",
            "39/39 - 3s - loss: 0.3297 - val_loss: 0.3909 - 3s/epoch - 69ms/step\n",
            "Epoch 2/50\n",
            "39/39 - 0s - loss: 0.0372 - val_loss: 0.0117 - 110ms/epoch - 3ms/step\n",
            "Epoch 3/50\n",
            "39/39 - 0s - loss: 0.0761 - val_loss: 0.0114 - 111ms/epoch - 3ms/step\n",
            "Epoch 4/50\n",
            "39/39 - 0s - loss: 0.0587 - val_loss: 0.0080 - 114ms/epoch - 3ms/step\n",
            "Epoch 5/50\n",
            "39/39 - 0s - loss: 0.0312 - val_loss: 0.0242 - 114ms/epoch - 3ms/step\n",
            "Epoch 6/50\n",
            "39/39 - 0s - loss: 0.0230 - val_loss: 0.0363 - 118ms/epoch - 3ms/step\n",
            "Epoch 7/50\n",
            "39/39 - 0s - loss: 0.0214 - val_loss: 0.0301 - 108ms/epoch - 3ms/step\n",
            "Epoch 8/50\n",
            "39/39 - 0s - loss: 0.0204 - val_loss: 0.0249 - 118ms/epoch - 3ms/step\n",
            "Epoch 9/50\n",
            "39/39 - 0s - loss: 0.0185 - val_loss: 0.0184 - 107ms/epoch - 3ms/step\n",
            "Epoch 10/50\n",
            "39/39 - 0s - loss: 0.0165 - val_loss: 0.0139 - 127ms/epoch - 3ms/step\n",
            "Epoch 11/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0133 - 126ms/epoch - 3ms/step\n",
            "Epoch 12/50\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0130 - 109ms/epoch - 3ms/step\n",
            "Epoch 13/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0157 - 122ms/epoch - 3ms/step\n",
            "Epoch 14/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0188 - 123ms/epoch - 3ms/step\n",
            "Epoch 15/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0193 - 110ms/epoch - 3ms/step\n",
            "Epoch 16/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0196 - 119ms/epoch - 3ms/step\n",
            "Epoch 17/50\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0187 - 127ms/epoch - 3ms/step\n",
            "Epoch 18/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0153 - 114ms/epoch - 3ms/step\n",
            "Epoch 19/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0160 - 116ms/epoch - 3ms/step\n",
            "Epoch 20/50\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0111 - 112ms/epoch - 3ms/step\n",
            "Epoch 21/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0094 - 111ms/epoch - 3ms/step\n",
            "Epoch 22/50\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0083 - 119ms/epoch - 3ms/step\n",
            "Epoch 23/50\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0083 - 125ms/epoch - 3ms/step\n",
            "Epoch 24/50\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0091 - 120ms/epoch - 3ms/step\n",
            "Epoch 25/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0091 - 108ms/epoch - 3ms/step\n",
            "Epoch 26/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0073 - 114ms/epoch - 3ms/step\n",
            "Epoch 27/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0075 - 126ms/epoch - 3ms/step\n",
            "Epoch 28/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0060 - 110ms/epoch - 3ms/step\n",
            "Epoch 29/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0069 - 116ms/epoch - 3ms/step\n",
            "Epoch 30/50\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0060 - 114ms/epoch - 3ms/step\n",
            "Epoch 31/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0067 - 115ms/epoch - 3ms/step\n",
            "Epoch 32/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 112ms/epoch - 3ms/step\n",
            "Epoch 33/50\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0059 - 118ms/epoch - 3ms/step\n",
            "Epoch 34/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0089 - 109ms/epoch - 3ms/step\n",
            "Epoch 35/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0068 - 112ms/epoch - 3ms/step\n",
            "Epoch 36/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 122ms/epoch - 3ms/step\n",
            "Epoch 37/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 114ms/epoch - 3ms/step\n",
            "Epoch 38/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 109ms/epoch - 3ms/step\n",
            "Epoch 39/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0060 - 116ms/epoch - 3ms/step\n",
            "Epoch 40/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0059 - 118ms/epoch - 3ms/step\n",
            "Epoch 41/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0059 - 118ms/epoch - 3ms/step\n",
            "Epoch 42/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0059 - 125ms/epoch - 3ms/step\n",
            "Epoch 43/50\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0060 - 112ms/epoch - 3ms/step\n",
            "Epoch 44/50\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0093 - 117ms/epoch - 3ms/step\n",
            "Epoch 45/50\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0098 - 128ms/epoch - 3ms/step\n",
            "Epoch 46/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0080 - 113ms/epoch - 3ms/step\n",
            "Epoch 47/50\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0059 - 117ms/epoch - 3ms/step\n",
            "Epoch 48/50\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0064 - 117ms/epoch - 3ms/step\n",
            "Epoch 49/50\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0065 - 107ms/epoch - 3ms/step\n",
            "Epoch 50/50\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0073 - 111ms/epoch - 3ms/step\n",
            "Epoch 1/100\n",
            "39/39 - 3s - loss: 0.3207 - val_loss: 0.4832 - 3s/epoch - 78ms/step\n",
            "Epoch 2/100\n",
            "39/39 - 0s - loss: 0.0566 - val_loss: 0.0392 - 192ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "39/39 - 0s - loss: 0.1034 - val_loss: 0.0838 - 175ms/epoch - 4ms/step\n",
            "Epoch 4/100\n",
            "39/39 - 0s - loss: 0.0561 - val_loss: 0.0201 - 165ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "39/39 - 0s - loss: 0.0513 - val_loss: 0.0137 - 138ms/epoch - 4ms/step\n",
            "Epoch 6/100\n",
            "39/39 - 0s - loss: 0.0272 - val_loss: 0.0145 - 139ms/epoch - 4ms/step\n",
            "Epoch 7/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0209 - 148ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0204 - 172ms/epoch - 4ms/step\n",
            "Epoch 9/100\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0187 - 188ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "39/39 - 0s - loss: 0.0141 - val_loss: 0.0166 - 179ms/epoch - 5ms/step\n",
            "Epoch 11/100\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0176 - 155ms/epoch - 4ms/step\n",
            "Epoch 12/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0168 - 182ms/epoch - 5ms/step\n",
            "Epoch 13/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0167 - 176ms/epoch - 5ms/step\n",
            "Epoch 14/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0154 - 191ms/epoch - 5ms/step\n",
            "Epoch 15/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0163 - 168ms/epoch - 4ms/step\n",
            "Epoch 16/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0193 - 161ms/epoch - 4ms/step\n",
            "Epoch 17/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0203 - 164ms/epoch - 4ms/step\n",
            "Epoch 18/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0208 - 185ms/epoch - 5ms/step\n",
            "Epoch 19/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0203 - 155ms/epoch - 4ms/step\n",
            "Epoch 20/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0214 - 120ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0215 - 107ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0219 - 115ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0208 - 114ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0207 - 104ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0206 - 108ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0205 - 130ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "39/39 - 0s - loss: 0.0144 - val_loss: 0.0207 - 118ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0207 - 141ms/epoch - 4ms/step\n",
            "Epoch 29/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0199 - 113ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0201 - 115ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0193 - 106ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0182 - 104ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0177 - 107ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0180 - 109ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0180 - 107ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0182 - 116ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0190 - 123ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0208 - 107ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0203 - 108ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0180 - 108ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0171 - 115ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0186 - 113ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0183 - 115ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0205 - 113ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0199 - 116ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0215 - 124ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0195 - 119ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0209 - 112ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0182 - 115ms/epoch - 3ms/step\n",
            "Epoch 50/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0204 - 106ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0196 - 109ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0202 - 110ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0193 - 107ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0202 - 108ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0196 - 119ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0208 - 107ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0202 - 109ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0202 - 115ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0191 - 103ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0187 - 115ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0192 - 117ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0185 - 116ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0185 - 119ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0197 - 124ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0186 - 114ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0190 - 112ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0191 - 111ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0196 - 114ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0209 - 115ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0219 - 111ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0208 - 116ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0207 - 106ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0203 - 122ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0192 - 120ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0197 - 110ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0203 - 105ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0192 - 112ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0183 - 113ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0186 - 112ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0188 - 115ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0192 - 120ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0190 - 124ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0188 - 110ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0193 - 107ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0191 - 112ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0195 - 112ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0188 - 108ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0193 - 114ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0196 - 113ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0192 - 114ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0193 - 116ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0191 - 106ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0188 - 111ms/epoch - 3ms/step\n",
            "Epoch 94/100\n",
            "39/39 - 0s - loss: 0.0147 - val_loss: 0.0195 - 109ms/epoch - 3ms/step\n",
            "Epoch 95/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0194 - 113ms/epoch - 3ms/step\n",
            "Epoch 96/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0191 - 109ms/epoch - 3ms/step\n",
            "Epoch 97/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0197 - 106ms/epoch - 3ms/step\n",
            "Epoch 98/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0194 - 114ms/epoch - 3ms/step\n",
            "Epoch 99/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0187 - 110ms/epoch - 3ms/step\n",
            "Epoch 100/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0189 - 115ms/epoch - 3ms/step\n",
            "Epoch 1/100\n",
            "39/39 - 4s - loss: 0.3297 - val_loss: 0.3909 - 4s/epoch - 94ms/step\n",
            "Epoch 2/100\n",
            "39/39 - 0s - loss: 0.0372 - val_loss: 0.0117 - 177ms/epoch - 5ms/step\n",
            "Epoch 3/100\n",
            "39/39 - 0s - loss: 0.0761 - val_loss: 0.0114 - 179ms/epoch - 5ms/step\n",
            "Epoch 4/100\n",
            "39/39 - 0s - loss: 0.0587 - val_loss: 0.0080 - 165ms/epoch - 4ms/step\n",
            "Epoch 5/100\n",
            "39/39 - 0s - loss: 0.0312 - val_loss: 0.0242 - 180ms/epoch - 5ms/step\n",
            "Epoch 6/100\n",
            "39/39 - 0s - loss: 0.0230 - val_loss: 0.0363 - 184ms/epoch - 5ms/step\n",
            "Epoch 7/100\n",
            "39/39 - 0s - loss: 0.0214 - val_loss: 0.0301 - 157ms/epoch - 4ms/step\n",
            "Epoch 8/100\n",
            "39/39 - 0s - loss: 0.0204 - val_loss: 0.0249 - 176ms/epoch - 5ms/step\n",
            "Epoch 9/100\n",
            "39/39 - 0s - loss: 0.0185 - val_loss: 0.0184 - 186ms/epoch - 5ms/step\n",
            "Epoch 10/100\n",
            "39/39 - 0s - loss: 0.0165 - val_loss: 0.0139 - 126ms/epoch - 3ms/step\n",
            "Epoch 11/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0133 - 130ms/epoch - 3ms/step\n",
            "Epoch 12/100\n",
            "39/39 - 0s - loss: 0.0142 - val_loss: 0.0130 - 120ms/epoch - 3ms/step\n",
            "Epoch 13/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0157 - 121ms/epoch - 3ms/step\n",
            "Epoch 14/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0188 - 111ms/epoch - 3ms/step\n",
            "Epoch 15/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0193 - 132ms/epoch - 3ms/step\n",
            "Epoch 16/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0196 - 119ms/epoch - 3ms/step\n",
            "Epoch 17/100\n",
            "39/39 - 0s - loss: 0.0149 - val_loss: 0.0187 - 120ms/epoch - 3ms/step\n",
            "Epoch 18/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0153 - 114ms/epoch - 3ms/step\n",
            "Epoch 19/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0160 - 117ms/epoch - 3ms/step\n",
            "Epoch 20/100\n",
            "39/39 - 0s - loss: 0.0145 - val_loss: 0.0111 - 118ms/epoch - 3ms/step\n",
            "Epoch 21/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0094 - 115ms/epoch - 3ms/step\n",
            "Epoch 22/100\n",
            "39/39 - 0s - loss: 0.0143 - val_loss: 0.0083 - 123ms/epoch - 3ms/step\n",
            "Epoch 23/100\n",
            "39/39 - 0s - loss: 0.0146 - val_loss: 0.0083 - 113ms/epoch - 3ms/step\n",
            "Epoch 24/100\n",
            "39/39 - 0s - loss: 0.0148 - val_loss: 0.0091 - 128ms/epoch - 3ms/step\n",
            "Epoch 25/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0091 - 122ms/epoch - 3ms/step\n",
            "Epoch 26/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0073 - 114ms/epoch - 3ms/step\n",
            "Epoch 27/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0075 - 117ms/epoch - 3ms/step\n",
            "Epoch 28/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0060 - 114ms/epoch - 3ms/step\n",
            "Epoch 29/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0069 - 116ms/epoch - 3ms/step\n",
            "Epoch 30/100\n",
            "39/39 - 0s - loss: 0.0150 - val_loss: 0.0060 - 119ms/epoch - 3ms/step\n",
            "Epoch 31/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0067 - 115ms/epoch - 3ms/step\n",
            "Epoch 32/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 126ms/epoch - 3ms/step\n",
            "Epoch 33/100\n",
            "39/39 - 0s - loss: 0.0151 - val_loss: 0.0059 - 125ms/epoch - 3ms/step\n",
            "Epoch 34/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0089 - 109ms/epoch - 3ms/step\n",
            "Epoch 35/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0068 - 118ms/epoch - 3ms/step\n",
            "Epoch 36/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 115ms/epoch - 3ms/step\n",
            "Epoch 37/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 117ms/epoch - 3ms/step\n",
            "Epoch 38/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0059 - 116ms/epoch - 3ms/step\n",
            "Epoch 39/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0060 - 111ms/epoch - 3ms/step\n",
            "Epoch 40/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0059 - 123ms/epoch - 3ms/step\n",
            "Epoch 41/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0059 - 133ms/epoch - 3ms/step\n",
            "Epoch 42/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0059 - 116ms/epoch - 3ms/step\n",
            "Epoch 43/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0060 - 124ms/epoch - 3ms/step\n",
            "Epoch 44/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0093 - 115ms/epoch - 3ms/step\n",
            "Epoch 45/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0098 - 121ms/epoch - 3ms/step\n",
            "Epoch 46/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0080 - 118ms/epoch - 3ms/step\n",
            "Epoch 47/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0059 - 110ms/epoch - 3ms/step\n",
            "Epoch 48/100\n",
            "39/39 - 0s - loss: 0.0152 - val_loss: 0.0064 - 113ms/epoch - 3ms/step\n",
            "Epoch 49/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0065 - 137ms/epoch - 4ms/step\n",
            "Epoch 50/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0073 - 118ms/epoch - 3ms/step\n",
            "Epoch 51/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0108 - 115ms/epoch - 3ms/step\n",
            "Epoch 52/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0110 - 121ms/epoch - 3ms/step\n",
            "Epoch 53/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0102 - 113ms/epoch - 3ms/step\n",
            "Epoch 54/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0101 - 130ms/epoch - 3ms/step\n",
            "Epoch 55/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0086 - 111ms/epoch - 3ms/step\n",
            "Epoch 56/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0113 - 112ms/epoch - 3ms/step\n",
            "Epoch 57/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0089 - 111ms/epoch - 3ms/step\n",
            "Epoch 58/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0115 - 128ms/epoch - 3ms/step\n",
            "Epoch 59/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0109 - 112ms/epoch - 3ms/step\n",
            "Epoch 60/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0101 - 119ms/epoch - 3ms/step\n",
            "Epoch 61/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0088 - 111ms/epoch - 3ms/step\n",
            "Epoch 62/100\n",
            "39/39 - 0s - loss: 0.0153 - val_loss: 0.0082 - 118ms/epoch - 3ms/step\n",
            "Epoch 63/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0097 - 114ms/epoch - 3ms/step\n",
            "Epoch 64/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0118 - 107ms/epoch - 3ms/step\n",
            "Epoch 65/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0113 - 109ms/epoch - 3ms/step\n",
            "Epoch 66/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0114 - 119ms/epoch - 3ms/step\n",
            "Epoch 67/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0112 - 111ms/epoch - 3ms/step\n",
            "Epoch 68/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0134 - 114ms/epoch - 3ms/step\n",
            "Epoch 69/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0142 - 112ms/epoch - 3ms/step\n",
            "Epoch 70/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0144 - 111ms/epoch - 3ms/step\n",
            "Epoch 71/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0132 - 116ms/epoch - 3ms/step\n",
            "Epoch 72/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0135 - 109ms/epoch - 3ms/step\n",
            "Epoch 73/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0154 - 110ms/epoch - 3ms/step\n",
            "Epoch 74/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0143 - 112ms/epoch - 3ms/step\n",
            "Epoch 75/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0149 - 125ms/epoch - 3ms/step\n",
            "Epoch 76/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0141 - 114ms/epoch - 3ms/step\n",
            "Epoch 77/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0160 - 120ms/epoch - 3ms/step\n",
            "Epoch 78/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0158 - 118ms/epoch - 3ms/step\n",
            "Epoch 79/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0171 - 113ms/epoch - 3ms/step\n",
            "Epoch 80/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0152 - 112ms/epoch - 3ms/step\n",
            "Epoch 81/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0171 - 114ms/epoch - 3ms/step\n",
            "Epoch 82/100\n",
            "39/39 - 0s - loss: 0.0159 - val_loss: 0.0162 - 109ms/epoch - 3ms/step\n",
            "Epoch 83/100\n",
            "39/39 - 0s - loss: 0.0160 - val_loss: 0.0168 - 114ms/epoch - 3ms/step\n",
            "Epoch 84/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0163 - 127ms/epoch - 3ms/step\n",
            "Epoch 85/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0155 - 120ms/epoch - 3ms/step\n",
            "Epoch 86/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0140 - 111ms/epoch - 3ms/step\n",
            "Epoch 87/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0155 - 107ms/epoch - 3ms/step\n",
            "Epoch 88/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0154 - 117ms/epoch - 3ms/step\n",
            "Epoch 89/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0165 - 118ms/epoch - 3ms/step\n",
            "Epoch 90/100\n",
            "39/39 - 0s - loss: 0.0158 - val_loss: 0.0163 - 118ms/epoch - 3ms/step\n",
            "Epoch 91/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0162 - 111ms/epoch - 3ms/step\n",
            "Epoch 92/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0148 - 116ms/epoch - 3ms/step\n",
            "Epoch 93/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0128 - 149ms/epoch - 4ms/step\n",
            "Epoch 94/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0153 - 179ms/epoch - 5ms/step\n",
            "Epoch 95/100\n",
            "39/39 - 0s - loss: 0.0157 - val_loss: 0.0154 - 205ms/epoch - 5ms/step\n",
            "Epoch 96/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0162 - 176ms/epoch - 5ms/step\n",
            "Epoch 97/100\n",
            "39/39 - 0s - loss: 0.0156 - val_loss: 0.0159 - 177ms/epoch - 5ms/step\n",
            "Epoch 98/100\n",
            "39/39 - 0s - loss: 0.0155 - val_loss: 0.0160 - 208ms/epoch - 5ms/step\n",
            "Epoch 99/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0164 - 161ms/epoch - 4ms/step\n",
            "Epoch 100/100\n",
            "39/39 - 0s - loss: 0.0154 - val_loss: 0.0157 - 179ms/epoch - 5ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "wb2 = Workbook()\n",
        "ws2 = wb2.active\n",
        "for m in models2:\n",
        "    # make a prediction\n",
        "    test_x2 = test_X\n",
        "    yhat = m.predict(test_x2)\n",
        "    inv_yhat = Preprocessing.inverse_scaler(yhat, scaler)\n",
        "    inv_y = Preprocessing.inverse_scaler(test_y.reshape(-1,1), scaler)\n",
        "    print(hyperparam2[i])\n",
        "    print(\"Epoch: \"+ str(lstms2[i].params['epochs']))\n",
        "    print(\"Neurons: \"+str(m.layers[0].units))\n",
        "\n",
        "    i = i+1\n",
        "    ws2['A'+str(i)] = 'DWT-LSTM'\n",
        "    ws2['B'+str(i)] = hyperparam2[i-1][0]\n",
        "    ws2['C'+str(i)] = hyperparam2[i-1][1]\n",
        "    ws2['D'+str(i)] = hyperparam2[i-1][2]\n",
        "\n",
        "    print('RMSE')\n",
        "    print(Evaluation.rmse(inv_y,inv_yhat))\n",
        "    ws2['E'+str(i)] = Evaluation.rmse(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAE')\n",
        "    print(Evaluation.mae(inv_y,inv_yhat))\n",
        "    ws2['F'+str(i)] = Evaluation.mae(inv_y,inv_yhat)\n",
        "\n",
        "    print('MAPE')\n",
        "    print(Evaluation.mape(inv_y,inv_yhat))\n",
        "    ws2['G'+str(i)] = Evaluation.mape(inv_y,inv_yhat)\n",
        "\n",
        "    NeuralNetwork.save_model(m, 1, 'BBCA',hyperparam2[i-1])\n",
        "    with open('DWT_LSTM_BBCA'+str(hyperparam2[i-1])+'.pkl', 'wb') as f:\n",
        "        pickle.dump(lstms2[i-1].history, f)\n",
        "wb2.save('DWT_LSTM_BBCA_result2.xlsx')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAbxjbvIfoJW",
        "outputId": "9d7ae02a-f7b0-4d23-9c21-dc0e98509019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n",
            "(32, 50, 20)\n",
            "Epoch: 50\n",
            "Neurons: 20\n",
            "RMSE\n",
            "111.09054458865496\n",
            "MAE\n",
            "107.60986328125\n",
            "MAPE\n",
            "1.1093800338273194\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "(32, 50, 50)\n",
            "Epoch: 50\n",
            "Neurons: 50\n",
            "RMSE\n",
            "49.585080928084444\n",
            "MAE\n",
            "38.43115234375\n",
            "MAPE\n",
            "0.39619744684278346\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "(32, 100, 20)\n",
            "Epoch: 100\n",
            "Neurons: 20\n",
            "RMSE\n",
            "104.37112636116638\n",
            "MAE\n",
            "99.7724609375\n",
            "MAPE\n",
            "1.0285820715206184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n",
            "(32, 100, 50)\n",
            "Epoch: 100\n",
            "Neurons: 50\n",
            "RMSE\n",
            "89.65995819996633\n",
            "MAE\n",
            "82.83837890625\n",
            "MAPE\n",
            "0.8540039062500001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmZS_wK6u3n9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}